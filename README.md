DESCRIPCIÓN BORRADOR

*en el notebook de tarea en español hay un mini texto, en la tarea de inglés al haber varios notebooks no se donde ponerlo, ni donde poner tabla comparativa de resultados.

Para la tarea de clasificación en inglés, nos enfocamos en estrategias de enriquecimiento de datos, aprovechando las capacidades de autoatención de los modelos transformers, utilizando exclusivamente los encoders de arquitecturas como BERT y RoBERTa.

Preprocesamiento de Datos: Se limpiaron los conjuntos de entrenamiento y prueba eliminando elementos como URLs para facilitar la interpretación correcta de los textos. Este preprocesamiento se aplicó tanto a datos en inglés como en español, asegurando consistencia en ambos conjuntos. Manejo del Desequilibrio de Clases: Se identificó un desequilibrio significativo en los datos, con una clara subrepresentación de la clase CONSPIRACY. Para abordar este problema, se implementó una estrategia de oversampling, pero con un enfoque diferenciador: los textos originales fueron traducidos a otro idioma utilizando modelos preentrenados de Hugging Face y luego traducidos de vuelta al idioma original. Esta técnica generó datos similares pero no idénticos, mitigando riesgos de overfitting. Adición de Información Contextual: Dada la subjetividad de la tarea, se exploraron estrategias para enriquecer los datos con información adicional. Inicialmente, se consideró utilizar modelos preentrenados para extraer características textuales como emociones, pero esta opción se descartó debido a su dependencia del sesgo del modelo seleccionado. Optamos por incorporar léxicos en inglés (emocionales y morales) que relacionan palabras clave en los textos con emociones y valores morales. La información extraída de estos léxicos se incluyó como un prompt añadido al final del texto original, indicando qué emoción y valor moral reflejaba el contenido. Experimentos y Ajustes: Se realizaron múltiples experimentos para identificar el modelo preentrenado más efectivo (comparando entre BERT base uncased y RoBERTa), evaluar el impacto del aumento de datos y ajustar hiperparámetros clave. También se exploraron configuraciones avanzadas, como el aumento del tamaño de batch, para mejorar los resultados del modelo. Resultados y Métricas: Los resultados fueron evaluados utilizando métricas como F1-score macro y micro, y el coeficiente MCC, según lo solicitado en la competencia original. El mejor desempeño se obtuvo con el modelo RoBERTa, en combinación con el aumento de datos mediante traducciones y la adición del contexto emocional y moral extraído de los léxicos. Este enfoque superó el baseline de la competencia PAN. Experimentación Adicional: Como parte de la exploración de técnicas avanzadas, modificamos la estructura base de RoBERTa añadiendo capas de atención múltiple y convoluciones, (siguiendo un enfoque basado en el paper Cheruku, R. et al. (2023) Sentiment classification with modified Roberta and recurrent neural networks - multimedia tools and applications, SpringerLink. Available at: https://link.springer.com/article/10.1007/s11042-023-16833-5 (Accessed: 22 November 2024) . Aunque no se lograron mejoras significativas, este experimento permitió aprender cómo alterar arquitecturas para tareas con alta subjetividad, como clasificar emociones y añadir metadatos textuales. También se realizó un experimento combinando las representaciones [CLS] de BERT y RoBERTa. Los embeddings de ambas arquitecturas (768 dimensiones cada uno) fueron concatenados para formar un vector de 1536 dimensiones, que se introdujo en una capa totalmente conectada para la clasificación binaria
