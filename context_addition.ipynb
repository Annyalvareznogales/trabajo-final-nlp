{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36527ad2-8ce8-4cf3-b2ce-4c8d3531ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import functools\n",
    "import numpy as np\n",
    "import warnings\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53835d9-a153-4db7-9e50-92dc3fa44137",
   "metadata": {},
   "source": [
    "# Depechemood++ \n",
    "Este cuaderno contiene las funciones necesarias para obtener el valor moral y emocional de los textos utilizando el enfoque basado en el léxico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94d59a-c302-476e-99dd-9843f43f0d78",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc43db74-eeb5-4f3e-b7a9-e66eca08611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emo_representation(words, emo_vocab=None, emotion_lex=None, n_emotions=None):\n",
    "    \"\"\"\n",
    "    Extrae una representación de emociones a partir de una lista de palabras y devuelve también\n",
    "    las palabras que contribuyen a esta representación.\n",
    "    \n",
    "    Args:\n",
    "    words (list of str): Lista de palabras del texto.\n",
    "    emo_vocab (set): Conjunto de palabras en el léxico emocional.\n",
    "    emotion_lex (dict): Diccionario que mapea palabras a sus vectores de emoción.\n",
    "    n_emotions (int): Número de emociones en los vectores de emoción.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Diccionario con 'emotion_vector' (representación promedio de emociones)\n",
    "          y 'matched_words' (palabras usadas en el cálculo).\n",
    "    \"\"\"\n",
    "    intersection = emo_vocab & set(words)\n",
    "    matched_words = list(intersection) \n",
    "    v = np.zeros((len(intersection), n_emotions))\n",
    "    \n",
    "    for i, word in enumerate(intersection):\n",
    "        v[i, :] = emotion_lex[word]\n",
    "    \n",
    "    # Calculamos el vector de emociones (usamos la media)\n",
    "    emotion_vector = np.mean(v, axis=0) if len(intersection) > 0 else np.zeros(n_emotions)\n",
    "    \n",
    "    # Retornamos tanto el vector de emociones como las palabras coincidentes\n",
    "    return {\n",
    "        'emotion_vector': emotion_vector,\n",
    "        'matched_words': matched_words\n",
    "    }\n",
    "\n",
    "    \n",
    "def dictionary_emotion(text):\n",
    "    \"\"\"\n",
    "    Convierte la lista puntuaciones de emociones en diccionario con emoción como clave\n",
    "    Args:\n",
    "    text (list): Lista de puntuaciones de emociones.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Diccionario con las emociones y sus respectivas emociones.\n",
    "    \"\"\"\n",
    "    test_keys = [\"fear\", \"amusement\", \"anger\",\"annoyance\",\"indifference\",\"happiness\",\"inspiration\",\"sadness\"]\n",
    "    dictionary = dict(map(lambda i,j : (i,j) , test_keys,text))\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def top_n_emotions_names(emotion_scores, n=3):\n",
    "    \"\"\"\n",
    "    Obtiene las n emociones con los puntajes más altos (solo nombres).\n",
    "    \n",
    "    Args:\n",
    "    emotion_scores (dict): Diccionario que mapea etiquetas de emociones a sus respectivos puntajes.\n",
    "    n (int): Número de emociones con los puntajes más altos a devolver.\n",
    "    \n",
    "    Returns:\n",
    "    list: Lista de las n emociones con mayores puntajes.\n",
    "    \"\"\"\n",
    "    sorted_emotions = sorted(emotion_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    return [emotion for emotion, _ in sorted_emotions[:n]]\n",
    "\n",
    "\n",
    "def get_max_emotion_name(emotion_scores):\n",
    "    \"\"\"\n",
    "    Obtiene el nombre de la emoción con el puntaje más alto.\n",
    "    \n",
    "    Args:\n",
    "    emotion_scores (dict): Diccionario que mapea etiquetas de emociones a sus respectivos puntajes.\n",
    "    \n",
    "    Returns:\n",
    "    str: El nombre de la emoción con el puntaje más alto.\n",
    "    \"\"\"\n",
    "    max_emotion = max(emotion_scores, key=emotion_scores.get)\n",
    "    return max_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f98ab-56a3-4bf1-ad52-8aaa59c7207c",
   "metadata": {},
   "source": [
    "# DepecheMood++ Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "138ac2ba-69a5-43b8-a92f-2befd4ef4186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32118/2593853609.py:12: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  lexicon_dict = lexicon.set_index('index').T.to_dict('list')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AFRAID</th>\n",
       "      <th>AMUSED</th>\n",
       "      <th>ANGRY</th>\n",
       "      <th>ANNOYED</th>\n",
       "      <th>DONT_CARE</th>\n",
       "      <th>HAPPY</th>\n",
       "      <th>INSPIRED</th>\n",
       "      <th>SAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>abstinence</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.215323</td>\n",
       "      <td>0.098104</td>\n",
       "      <td>0.282082</td>\n",
       "      <td>0.090112</td>\n",
       "      <td>0.066984</td>\n",
       "      <td>0.203085</td>\n",
       "      <td>0.033519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.044336</td>\n",
       "      <td>0.201894</td>\n",
       "      <td>0.056911</td>\n",
       "      <td>0.090680</td>\n",
       "      <td>0.075127</td>\n",
       "      <td>0.146059</td>\n",
       "      <td>0.328487</td>\n",
       "      <td>0.056506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>abstraction</td>\n",
       "      <td>0.099769</td>\n",
       "      <td>0.229726</td>\n",
       "      <td>0.056256</td>\n",
       "      <td>0.043741</td>\n",
       "      <td>0.096377</td>\n",
       "      <td>0.093452</td>\n",
       "      <td>0.380002</td>\n",
       "      <td>0.000676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>absurd</td>\n",
       "      <td>0.049905</td>\n",
       "      <td>0.149006</td>\n",
       "      <td>0.122266</td>\n",
       "      <td>0.279938</td>\n",
       "      <td>0.138893</td>\n",
       "      <td>0.058723</td>\n",
       "      <td>0.136655</td>\n",
       "      <td>0.064614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>absurdity</td>\n",
       "      <td>0.071087</td>\n",
       "      <td>0.211499</td>\n",
       "      <td>0.063726</td>\n",
       "      <td>0.113263</td>\n",
       "      <td>0.143294</td>\n",
       "      <td>0.107244</td>\n",
       "      <td>0.205989</td>\n",
       "      <td>0.083899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>abu</td>\n",
       "      <td>0.178752</td>\n",
       "      <td>0.076420</td>\n",
       "      <td>0.287083</td>\n",
       "      <td>0.098101</td>\n",
       "      <td>0.050531</td>\n",
       "      <td>0.089705</td>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.139545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>abubakar</td>\n",
       "      <td>0.170586</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.320873</td>\n",
       "      <td>0.062468</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>0.076771</td>\n",
       "      <td>0.081872</td>\n",
       "      <td>0.264151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>abucay</td>\n",
       "      <td>0.214619</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.154594</td>\n",
       "      <td>0.075068</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>0.008931</td>\n",
       "      <td>0.495835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>abuda</td>\n",
       "      <td>0.017440</td>\n",
       "      <td>0.104254</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159592</td>\n",
       "      <td>0.347372</td>\n",
       "      <td>0.349145</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>abueva</td>\n",
       "      <td>0.033035</td>\n",
       "      <td>0.138778</td>\n",
       "      <td>0.031825</td>\n",
       "      <td>0.231798</td>\n",
       "      <td>0.107679</td>\n",
       "      <td>0.260889</td>\n",
       "      <td>0.125636</td>\n",
       "      <td>0.070361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>abuja</td>\n",
       "      <td>0.343619</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>0.319963</td>\n",
       "      <td>0.026561</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.039309</td>\n",
       "      <td>0.071419</td>\n",
       "      <td>0.131980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>abul</td>\n",
       "      <td>0.221446</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.138546</td>\n",
       "      <td>0.040776</td>\n",
       "      <td>0.054335</td>\n",
       "      <td>0.285240</td>\n",
       "      <td>0.082272</td>\n",
       "      <td>0.172258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>abunda</td>\n",
       "      <td>0.037943</td>\n",
       "      <td>0.090093</td>\n",
       "      <td>0.064994</td>\n",
       "      <td>0.324131</td>\n",
       "      <td>0.373164</td>\n",
       "      <td>0.034186</td>\n",
       "      <td>0.055907</td>\n",
       "      <td>0.019582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>abundabar</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>0.116810</td>\n",
       "      <td>0.039311</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.221418</td>\n",
       "      <td>0.268785</td>\n",
       "      <td>0.220210</td>\n",
       "      <td>0.004526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>abundance</td>\n",
       "      <td>0.127968</td>\n",
       "      <td>0.185625</td>\n",
       "      <td>0.074535</td>\n",
       "      <td>0.047243</td>\n",
       "      <td>0.094646</td>\n",
       "      <td>0.101767</td>\n",
       "      <td>0.230783</td>\n",
       "      <td>0.137434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>abundant</td>\n",
       "      <td>0.076033</td>\n",
       "      <td>0.114169</td>\n",
       "      <td>0.108496</td>\n",
       "      <td>0.156828</td>\n",
       "      <td>0.080399</td>\n",
       "      <td>0.116447</td>\n",
       "      <td>0.216746</td>\n",
       "      <td>0.130881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>abundantly</td>\n",
       "      <td>0.326954</td>\n",
       "      <td>0.066280</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.078723</td>\n",
       "      <td>0.055252</td>\n",
       "      <td>0.100570</td>\n",
       "      <td>0.257151</td>\n",
       "      <td>0.109216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>abundo</td>\n",
       "      <td>0.137028</td>\n",
       "      <td>0.048468</td>\n",
       "      <td>0.054880</td>\n",
       "      <td>0.133757</td>\n",
       "      <td>0.186433</td>\n",
       "      <td>0.049543</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.028089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>aburizal</td>\n",
       "      <td>0.277072</td>\n",
       "      <td>0.147915</td>\n",
       "      <td>0.059504</td>\n",
       "      <td>0.216964</td>\n",
       "      <td>0.112482</td>\n",
       "      <td>0.048441</td>\n",
       "      <td>0.134939</td>\n",
       "      <td>0.002683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>abuse</td>\n",
       "      <td>0.056160</td>\n",
       "      <td>0.097416</td>\n",
       "      <td>0.295551</td>\n",
       "      <td>0.141379</td>\n",
       "      <td>0.112864</td>\n",
       "      <td>0.076710</td>\n",
       "      <td>0.110763</td>\n",
       "      <td>0.109157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>abused</td>\n",
       "      <td>0.055760</td>\n",
       "      <td>0.101987</td>\n",
       "      <td>0.314262</td>\n",
       "      <td>0.153767</td>\n",
       "      <td>0.122719</td>\n",
       "      <td>0.056993</td>\n",
       "      <td>0.114206</td>\n",
       "      <td>0.080305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>abuser</td>\n",
       "      <td>0.026195</td>\n",
       "      <td>0.058301</td>\n",
       "      <td>0.348694</td>\n",
       "      <td>0.162416</td>\n",
       "      <td>0.118499</td>\n",
       "      <td>0.055309</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.142985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>abusive</td>\n",
       "      <td>0.039779</td>\n",
       "      <td>0.150547</td>\n",
       "      <td>0.222798</td>\n",
       "      <td>0.141565</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>0.089611</td>\n",
       "      <td>0.173115</td>\n",
       "      <td>0.067899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>abuyog</td>\n",
       "      <td>0.116677</td>\n",
       "      <td>0.266045</td>\n",
       "      <td>0.172353</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.058638</td>\n",
       "      <td>0.076854</td>\n",
       "      <td>0.285581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>abuyot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.906555</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>abuyuan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182477</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.061210</td>\n",
       "      <td>0.740824</td>\n",
       "      <td>0.014444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>abuza</td>\n",
       "      <td>0.067928</td>\n",
       "      <td>0.179185</td>\n",
       "      <td>0.258139</td>\n",
       "      <td>0.210899</td>\n",
       "      <td>0.075455</td>\n",
       "      <td>0.050679</td>\n",
       "      <td>0.107362</td>\n",
       "      <td>0.050353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>abuzz</td>\n",
       "      <td>0.053724</td>\n",
       "      <td>0.218374</td>\n",
       "      <td>0.127568</td>\n",
       "      <td>0.203881</td>\n",
       "      <td>0.176975</td>\n",
       "      <td>0.071104</td>\n",
       "      <td>0.088831</td>\n",
       "      <td>0.059544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>aby</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>0.121509</td>\n",
       "      <td>0.037623</td>\n",
       "      <td>0.091688</td>\n",
       "      <td>0.139282</td>\n",
       "      <td>0.307828</td>\n",
       "      <td>0.214683</td>\n",
       "      <td>0.070721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>abyan</td>\n",
       "      <td>0.688082</td>\n",
       "      <td>0.043374</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.099204</td>\n",
       "      <td>0.088333</td>\n",
       "      <td>0.061228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>abysmal</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>0.279783</td>\n",
       "      <td>0.039009</td>\n",
       "      <td>0.059358</td>\n",
       "      <td>0.077869</td>\n",
       "      <td>0.072602</td>\n",
       "      <td>0.167398</td>\n",
       "      <td>0.291240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>abyss</td>\n",
       "      <td>0.274304</td>\n",
       "      <td>0.100256</td>\n",
       "      <td>0.031675</td>\n",
       "      <td>0.155087</td>\n",
       "      <td>0.134105</td>\n",
       "      <td>0.057668</td>\n",
       "      <td>0.150973</td>\n",
       "      <td>0.095933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>ac</td>\n",
       "      <td>0.027554</td>\n",
       "      <td>0.176161</td>\n",
       "      <td>0.073688</td>\n",
       "      <td>0.094204</td>\n",
       "      <td>0.103708</td>\n",
       "      <td>0.208941</td>\n",
       "      <td>0.177484</td>\n",
       "      <td>0.138259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>aca</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522575</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185995</td>\n",
       "      <td>0.261742</td>\n",
       "      <td>0.023395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>acacia</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>0.102455</td>\n",
       "      <td>0.246556</td>\n",
       "      <td>0.074762</td>\n",
       "      <td>0.038166</td>\n",
       "      <td>0.155966</td>\n",
       "      <td>0.069958</td>\n",
       "      <td>0.307324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>academe</td>\n",
       "      <td>0.028203</td>\n",
       "      <td>0.099362</td>\n",
       "      <td>0.096089</td>\n",
       "      <td>0.201012</td>\n",
       "      <td>0.071202</td>\n",
       "      <td>0.140738</td>\n",
       "      <td>0.314711</td>\n",
       "      <td>0.048681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>academia</td>\n",
       "      <td>0.020313</td>\n",
       "      <td>0.116956</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>0.141325</td>\n",
       "      <td>0.095854</td>\n",
       "      <td>0.088940</td>\n",
       "      <td>0.349227</td>\n",
       "      <td>0.130907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>academic</td>\n",
       "      <td>0.054028</td>\n",
       "      <td>0.104834</td>\n",
       "      <td>0.134043</td>\n",
       "      <td>0.184353</td>\n",
       "      <td>0.118753</td>\n",
       "      <td>0.113672</td>\n",
       "      <td>0.230901</td>\n",
       "      <td>0.059416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>academically</td>\n",
       "      <td>0.118921</td>\n",
       "      <td>0.022205</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>0.074103</td>\n",
       "      <td>0.043302</td>\n",
       "      <td>0.063773</td>\n",
       "      <td>0.408518</td>\n",
       "      <td>0.185648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>academician</td>\n",
       "      <td>0.057135</td>\n",
       "      <td>0.170464</td>\n",
       "      <td>0.096727</td>\n",
       "      <td>0.143521</td>\n",
       "      <td>0.194696</td>\n",
       "      <td>0.065802</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>0.043426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>academics</td>\n",
       "      <td>0.189434</td>\n",
       "      <td>0.042676</td>\n",
       "      <td>0.138679</td>\n",
       "      <td>0.065363</td>\n",
       "      <td>0.061785</td>\n",
       "      <td>0.140825</td>\n",
       "      <td>0.261957</td>\n",
       "      <td>0.099280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>academy</td>\n",
       "      <td>0.051239</td>\n",
       "      <td>0.174380</td>\n",
       "      <td>0.096496</td>\n",
       "      <td>0.135441</td>\n",
       "      <td>0.140832</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.180511</td>\n",
       "      <td>0.095601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>acai</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149949</td>\n",
       "      <td>0.821686</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>acapella</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158348</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.132501</td>\n",
       "      <td>0.161494</td>\n",
       "      <td>0.181924</td>\n",
       "      <td>0.297145</td>\n",
       "      <td>0.067577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>acapulco</td>\n",
       "      <td>0.336623</td>\n",
       "      <td>0.026459</td>\n",
       "      <td>0.042815</td>\n",
       "      <td>0.073475</td>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.089630</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.396802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>acars</td>\n",
       "      <td>0.312897</td>\n",
       "      <td>0.070512</td>\n",
       "      <td>0.070181</td>\n",
       "      <td>0.116596</td>\n",
       "      <td>0.074663</td>\n",
       "      <td>0.028254</td>\n",
       "      <td>0.045370</td>\n",
       "      <td>0.281528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>acb</td>\n",
       "      <td>0.104052</td>\n",
       "      <td>0.323297</td>\n",
       "      <td>0.022811</td>\n",
       "      <td>0.040599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174475</td>\n",
       "      <td>0.334234</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>accc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145531</td>\n",
       "      <td>0.711842</td>\n",
       "      <td>0.021838</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.058712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>accede</td>\n",
       "      <td>0.040570</td>\n",
       "      <td>0.092148</td>\n",
       "      <td>0.154834</td>\n",
       "      <td>0.339071</td>\n",
       "      <td>0.086374</td>\n",
       "      <td>0.073288</td>\n",
       "      <td>0.103819</td>\n",
       "      <td>0.109897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>accelerate</td>\n",
       "      <td>0.140127</td>\n",
       "      <td>0.134516</td>\n",
       "      <td>0.101077</td>\n",
       "      <td>0.124338</td>\n",
       "      <td>0.115504</td>\n",
       "      <td>0.135837</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.110802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>accelerated</td>\n",
       "      <td>0.073764</td>\n",
       "      <td>0.033713</td>\n",
       "      <td>0.092514</td>\n",
       "      <td>0.113356</td>\n",
       "      <td>0.088228</td>\n",
       "      <td>0.209749</td>\n",
       "      <td>0.322806</td>\n",
       "      <td>0.065871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index    AFRAID    AMUSED     ANGRY   ANNOYED  DONT_CARE  \\\n",
       "200    abstinence  0.010791  0.215323  0.098104  0.282082   0.090112   \n",
       "201      abstract  0.044336  0.201894  0.056911  0.090680   0.075127   \n",
       "202   abstraction  0.099769  0.229726  0.056256  0.043741   0.096377   \n",
       "203        absurd  0.049905  0.149006  0.122266  0.279938   0.138893   \n",
       "204     absurdity  0.071087  0.211499  0.063726  0.113263   0.143294   \n",
       "205           abu  0.178752  0.076420  0.287083  0.098101   0.050531   \n",
       "206      abubakar  0.170586  0.005417  0.320873  0.062468   0.017862   \n",
       "207        abucay  0.214619  0.025325  0.154594  0.075068   0.010297   \n",
       "208         abuda  0.017440  0.104254  0.022197  0.000000   0.159592   \n",
       "209        abueva  0.033035  0.138778  0.031825  0.231798   0.107679   \n",
       "210         abuja  0.343619  0.010278  0.319963  0.026561   0.056872   \n",
       "211          abul  0.221446  0.005126  0.138546  0.040776   0.054335   \n",
       "212        abunda  0.037943  0.090093  0.064994  0.324131   0.373164   \n",
       "213     abundabar  0.017273  0.116810  0.039311  0.111667   0.221418   \n",
       "214     abundance  0.127968  0.185625  0.074535  0.047243   0.094646   \n",
       "215      abundant  0.076033  0.114169  0.108496  0.156828   0.080399   \n",
       "216    abundantly  0.326954  0.066280  0.005855  0.078723   0.055252   \n",
       "217        abundo  0.137028  0.048468  0.054880  0.133757   0.186433   \n",
       "218      aburizal  0.277072  0.147915  0.059504  0.216964   0.112482   \n",
       "219         abuse  0.056160  0.097416  0.295551  0.141379   0.112864   \n",
       "220        abused  0.055760  0.101987  0.314262  0.153767   0.122719   \n",
       "221        abuser  0.026195  0.058301  0.348694  0.162416   0.118499   \n",
       "222       abusive  0.039779  0.150547  0.222798  0.141565   0.114687   \n",
       "223        abuyog  0.116677  0.266045  0.172353  0.015956   0.007896   \n",
       "224        abuyot  0.000000  0.056431  0.000000  0.000000   0.000000   \n",
       "225       abuyuan  0.000000  0.182477  0.000218  0.000388   0.000439   \n",
       "226         abuza  0.067928  0.179185  0.258139  0.210899   0.075455   \n",
       "227         abuzz  0.053724  0.218374  0.127568  0.203881   0.176975   \n",
       "228           aby  0.016665  0.121509  0.037623  0.091688   0.139282   \n",
       "229         abyan  0.688082  0.043374  0.015904  0.003443   0.000433   \n",
       "230       abysmal  0.012740  0.279783  0.039009  0.059358   0.077869   \n",
       "231         abyss  0.274304  0.100256  0.031675  0.155087   0.134105   \n",
       "232            ac  0.027554  0.176161  0.073688  0.094204   0.103708   \n",
       "233           aca  0.000000  0.522575  0.006293  0.000000   0.000000   \n",
       "234        acacia  0.004814  0.102455  0.246556  0.074762   0.038166   \n",
       "235       academe  0.028203  0.099362  0.096089  0.201012   0.071202   \n",
       "236      academia  0.020313  0.116956  0.056478  0.141325   0.095854   \n",
       "237      academic  0.054028  0.104834  0.134043  0.184353   0.118753   \n",
       "238  academically  0.118921  0.022205  0.083531  0.074103   0.043302   \n",
       "239   academician  0.057135  0.170464  0.096727  0.143521   0.194696   \n",
       "240     academics  0.189434  0.042676  0.138679  0.065363   0.061785   \n",
       "241       academy  0.051239  0.174380  0.096496  0.135441   0.140832   \n",
       "242          acai  0.000000  0.018369  0.000000  0.000000   0.149949   \n",
       "243      acapella  0.000000  0.158348  0.001010  0.132501   0.161494   \n",
       "244      acapulco  0.336623  0.026459  0.042815  0.073475   0.017308   \n",
       "245         acars  0.312897  0.070512  0.070181  0.116596   0.074663   \n",
       "246           acb  0.104052  0.323297  0.022811  0.040599   0.000000   \n",
       "247          accc  0.000000  0.043861  0.000000  0.145531   0.711842   \n",
       "248        accede  0.040570  0.092148  0.154834  0.339071   0.086374   \n",
       "249    accelerate  0.140127  0.134516  0.101077  0.124338   0.115504   \n",
       "250   accelerated  0.073764  0.033713  0.092514  0.113356   0.088228   \n",
       "\n",
       "        HAPPY  INSPIRED       SAD  \n",
       "200  0.066984  0.203085  0.033519  \n",
       "201  0.146059  0.328487  0.056506  \n",
       "202  0.093452  0.380002  0.000676  \n",
       "203  0.058723  0.136655  0.064614  \n",
       "204  0.107244  0.205989  0.083899  \n",
       "205  0.089705  0.079862  0.139545  \n",
       "206  0.076771  0.081872  0.264151  \n",
       "207  0.015331  0.008931  0.495835  \n",
       "208  0.347372  0.349145  0.000000  \n",
       "209  0.260889  0.125636  0.070361  \n",
       "210  0.039309  0.071419  0.131980  \n",
       "211  0.285240  0.082272  0.172258  \n",
       "212  0.034186  0.055907  0.019582  \n",
       "213  0.268785  0.220210  0.004526  \n",
       "214  0.101767  0.230783  0.137434  \n",
       "215  0.116447  0.216746  0.130881  \n",
       "216  0.100570  0.257151  0.109216  \n",
       "217  0.049543  0.361802  0.028089  \n",
       "218  0.048441  0.134939  0.002683  \n",
       "219  0.076710  0.110763  0.109157  \n",
       "220  0.056993  0.114206  0.080305  \n",
       "221  0.055309  0.087600  0.142985  \n",
       "222  0.089611  0.173115  0.067899  \n",
       "223  0.058638  0.076854  0.285581  \n",
       "224  0.037014  0.906555  0.000000  \n",
       "225  0.061210  0.740824  0.014444  \n",
       "226  0.050679  0.107362  0.050353  \n",
       "227  0.071104  0.088831  0.059544  \n",
       "228  0.307828  0.214683  0.070721  \n",
       "229  0.099204  0.088333  0.061228  \n",
       "230  0.072602  0.167398  0.291240  \n",
       "231  0.057668  0.150973  0.095933  \n",
       "232  0.208941  0.177484  0.138259  \n",
       "233  0.185995  0.261742  0.023395  \n",
       "234  0.155966  0.069958  0.307324  \n",
       "235  0.140738  0.314711  0.048681  \n",
       "236  0.088940  0.349227  0.130907  \n",
       "237  0.113672  0.230901  0.059416  \n",
       "238  0.063773  0.408518  0.185648  \n",
       "239  0.065802  0.228228  0.043426  \n",
       "240  0.140825  0.261957  0.099280  \n",
       "241  0.125500  0.180511  0.095601  \n",
       "242  0.821686  0.009996  0.000000  \n",
       "243  0.181924  0.297145  0.067577  \n",
       "244  0.089630  0.016889  0.396802  \n",
       "245  0.028254  0.045370  0.281528  \n",
       "246  0.174475  0.334234  0.000531  \n",
       "247  0.021838  0.018217  0.058712  \n",
       "248  0.073288  0.103819  0.109897  \n",
       "249  0.135837  0.137800  0.110802  \n",
       "250  0.209749  0.322806  0.065871  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the DepecheMood lexicon\n",
    "#lexicon=pd.read_csv('DATASETS/DepecheMood_english_lemma_full.tsv',sep='\\t',index_col=[0])\n",
    "#lexicon.to_csv('DATASETS/DepecheMood_english_lemma_full.csv')\n",
    "\n",
    "#Filter lexicon to include only rows with 'freq' >= , 134278 values were discarded (23%), 41314 lemmas\n",
    "lexicon=pd.read_csv('DepecheMood_english_lemma_full.csv',index_col=[0])\n",
    "lexicon=lexicon[lexicon['freq'] >= 10] \n",
    "\n",
    "#Convert the lexicon to a dictionary\n",
    "lexicon=lexicon.drop('freq',axis=1)\n",
    "lexicon=lexicon.reset_index()\n",
    "lexicon_dict = lexicon.set_index('index').T.to_dict('list')\n",
    "#lexicon_dict\n",
    "#lexicon.loc[200:250,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee42491-e11e-48e4-a0bb-7e5942ddc5cf",
   "metadata": {},
   "source": [
    "## Emotion Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e0e1f66-5332-420a-9ac2-7810d657356c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'massive australian senator malcolm roberts expose nanotech find covid vaccine say genocide politician expose share lauraabolichannel'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/train/dataset_en_train_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d813e34-15a3-4e59-bcbe-be1b5dd2fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos las transformaciones de emociones\n",
    "emo_vocab = set(lexicon_dict.keys())\n",
    "n_emotions = 8  # Número de emociones\n",
    "\n",
    "# Creamos listas vacías para almacenar los resultados\n",
    "matched_words_list = []\n",
    "top_3_emotions_list = []\n",
    "max_emotion_list = []\n",
    "\n",
    "# Actualizamos el bucle para usar el nuevo nombre de la función\n",
    "for text in df['text']:\n",
    "    # Extraemos el vector de emociones y las palabras coincidentes\n",
    "    data = extract_emo_representation(text.split(' '), emo_vocab, lexicon_dict, n_emotions)\n",
    "    emotion_vector = data['emotion_vector']\n",
    "    matched_words = data['matched_words']\n",
    "    \n",
    "    # Convertimos el vector de emociones en un diccionario\n",
    "    emotion_scores = dictionary_emotion(emotion_vector)\n",
    "    \n",
    "    # Calculamos los resultados necesarios\n",
    "    top_3_emotions = top_n_emotions_names(emotion_scores, 3)  # Obtenemos solo los nombres\n",
    "    max_emotion = get_max_emotion_name(emotion_scores)  # Obtenemos solo el nombre\n",
    "    \n",
    "    # Guardamos los resultados en las listas\n",
    "    matched_words_list.append(matched_words)\n",
    "    top_3_emotions_list.append(top_3_emotions)\n",
    "    max_emotion_list.append(max_emotion)\n",
    "\n",
    "# Añadimos las nuevas columnas al DataFrame\n",
    "df['matched_words'] = matched_words_list\n",
    "df['top_3_emotions'] = top_3_emotions_list\n",
    "df['max_emotion'] = max_emotion_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66238b35-27b5-46b1-a332-e1c20a543b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>annotations</th>\n",
       "      <th>spacy_tokens</th>\n",
       "      <th>matched_words</th>\n",
       "      <th>top_3_emotions</th>\n",
       "      <th>max_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5206</td>\n",
       "      <td>this is massive australian senator malcolm rob...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>[{'span_text': 'Australian Senator Malcolm Rob...</td>\n",
       "      <td>WyJUSElTIiwgIklTIiwgIk1BU1NJVkUiLCAiQXVzdHJhbG...</td>\n",
       "      <td>[malcolm, senator, first, roberts, found, aust...</td>\n",
       "      <td>[inspiration, amusement, anger]</td>\n",
       "      <td>inspiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1387</td>\n",
       "      <td>i m deeply concerned that the push to vaccinat...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'I ’m deeply concerned that the...</td>\n",
       "      <td>WyJcdTIwMWMiLCAiSSIsICJcdTIwMTltIiwgImRlZXBseS...</td>\n",
       "      <td>[push, young, texas, experiment, nothing, conc...</td>\n",
       "      <td>[inspiration, amusement, fear]</td>\n",
       "      <td>inspiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13116</td>\n",
       "      <td>they wanted to know your vaccination status an...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'someone who died suddenly', 'c...</td>\n",
       "      <td>WyIyMDIxIiwgIjoiLCAiVGhleSIsICJ3YW50ZWQiLCAidG...</td>\n",
       "      <td>[nt, be, allowed, know, want, who, someone, su...</td>\n",
       "      <td>[inspiration, indifference, amusement]</td>\n",
       "      <td>inspiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11439</td>\n",
       "      <td>anthony fauci once again defended brutal chine...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'brutal Chinese lockdowns', 'ca...</td>\n",
       "      <td>WyJBbnRob255IiwgIkZhdWNpIiwgIm9uY2UiLCAiYWdhaW...</td>\n",
       "      <td>[communist, forcefully, okay, people, brutal, ...</td>\n",
       "      <td>[anger, annoyance, inspiration]</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98</td>\n",
       "      <td>proof has emerged showing that death from wuha...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'death from Wuhan coronavirus (...</td>\n",
       "      <td>WyJQcm9vZiIsICJoYXMiLCAiZW1lcmdlZCIsICJzaG93aW...</td>\n",
       "      <td>[alive, also, creation, death, proteins, body,...</td>\n",
       "      <td>[inspiration, amusement, fear]</td>\n",
       "      <td>inspiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>4829</td>\n",
       "      <td>police in australia are warning that unvaccina...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'Police in Australia', 'categor...</td>\n",
       "      <td>WyJQb2xpY2UiLCAiaW4iLCAiQXVzdHJhbGlhIiwgImFyZS...</td>\n",
       "      <td>[will, double, receive, police, australia, apa...</td>\n",
       "      <td>[anger, inspiration, sadness]</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>10899</td>\n",
       "      <td>i personally do nt believe putin would set off...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>[{'span_text': 'Deep State', 'category': 'AGEN...</td>\n",
       "      <td>WyJJIiwgInBlcnNvbmFsbHkiLCAiZG8iLCAiblx1MjAxOX...</td>\n",
       "      <td>[also, filled, know, off, unchecked, may, deep...</td>\n",
       "      <td>[inspiration, amusement, annoyance]</td>\n",
       "      <td>inspiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>10637</td>\n",
       "      <td>pfizer lied we know that there s no doubt abou...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'Pfizer', 'category': 'AGENT', ...</td>\n",
       "      <td>WyJQZml6ZXIiLCAibGllZCIsICIuIiwgIldlIiwgImtub3...</td>\n",
       "      <td>[own, health, recorded, know, road, can, europ...</td>\n",
       "      <td>[annoyance, amusement, inspiration]</td>\n",
       "      <td>annoyance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>11338</td>\n",
       "      <td>it is utterly bizarre and inexplicable dr john...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'Dr. John Campbell', 'category'...</td>\n",
       "      <td>WyJcIiIsICJJdCIsICJpcyIsICJ1dHRlcmx5IiwgImJpem...</td>\n",
       "      <td>[rollout, vaccination, inexplicable, thank, bi...</td>\n",
       "      <td>[inspiration, amusement, indifference]</td>\n",
       "      <td>inspiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>892</td>\n",
       "      <td>i do nt know about you but i m getting extreme...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>[{'span_text': 'the deep state cabal', 'catego...</td>\n",
       "      <td>WyJJIiwgImRvIiwgIm4ndCIsICJrbm93IiwgImFib3V0Ii...</td>\n",
       "      <td>[page, self, know, foot, need, deep, psyche, a...</td>\n",
       "      <td>[inspiration, amusement, annoyance]</td>\n",
       "      <td>inspiration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text    category  \\\n",
       "0      5206  this is massive australian senator malcolm rob...  CONSPIRACY   \n",
       "1      1387  i m deeply concerned that the push to vaccinat...    CRITICAL   \n",
       "2     13116  they wanted to know your vaccination status an...    CRITICAL   \n",
       "3     11439  anthony fauci once again defended brutal chine...    CRITICAL   \n",
       "4        98  proof has emerged showing that death from wuha...    CRITICAL   \n",
       "...     ...                                                ...         ...   \n",
       "3995   4829  police in australia are warning that unvaccina...    CRITICAL   \n",
       "3996  10899  i personally do nt believe putin would set off...  CONSPIRACY   \n",
       "3997  10637  pfizer lied we know that there s no doubt abou...    CRITICAL   \n",
       "3998  11338  it is utterly bizarre and inexplicable dr john...    CRITICAL   \n",
       "3999    892  i do nt know about you but i m getting extreme...  CONSPIRACY   \n",
       "\n",
       "                                            annotations  \\\n",
       "0     [{'span_text': 'Australian Senator Malcolm Rob...   \n",
       "1     [{'span_text': 'I ’m deeply concerned that the...   \n",
       "2     [{'span_text': 'someone who died suddenly', 'c...   \n",
       "3     [{'span_text': 'brutal Chinese lockdowns', 'ca...   \n",
       "4     [{'span_text': 'death from Wuhan coronavirus (...   \n",
       "...                                                 ...   \n",
       "3995  [{'span_text': 'Police in Australia', 'categor...   \n",
       "3996  [{'span_text': 'Deep State', 'category': 'AGEN...   \n",
       "3997  [{'span_text': 'Pfizer', 'category': 'AGENT', ...   \n",
       "3998  [{'span_text': 'Dr. John Campbell', 'category'...   \n",
       "3999  [{'span_text': 'the deep state cabal', 'catego...   \n",
       "\n",
       "                                           spacy_tokens  \\\n",
       "0     WyJUSElTIiwgIklTIiwgIk1BU1NJVkUiLCAiQXVzdHJhbG...   \n",
       "1     WyJcdTIwMWMiLCAiSSIsICJcdTIwMTltIiwgImRlZXBseS...   \n",
       "2     WyIyMDIxIiwgIjoiLCAiVGhleSIsICJ3YW50ZWQiLCAidG...   \n",
       "3     WyJBbnRob255IiwgIkZhdWNpIiwgIm9uY2UiLCAiYWdhaW...   \n",
       "4     WyJQcm9vZiIsICJoYXMiLCAiZW1lcmdlZCIsICJzaG93aW...   \n",
       "...                                                 ...   \n",
       "3995  WyJQb2xpY2UiLCAiaW4iLCAiQXVzdHJhbGlhIiwgImFyZS...   \n",
       "3996  WyJJIiwgInBlcnNvbmFsbHkiLCAiZG8iLCAiblx1MjAxOX...   \n",
       "3997  WyJQZml6ZXIiLCAibGllZCIsICIuIiwgIldlIiwgImtub3...   \n",
       "3998  WyJcIiIsICJJdCIsICJpcyIsICJ1dHRlcmx5IiwgImJpem...   \n",
       "3999  WyJJIiwgImRvIiwgIm4ndCIsICJrbm93IiwgImFib3V0Ii...   \n",
       "\n",
       "                                          matched_words  \\\n",
       "0     [malcolm, senator, first, roberts, found, aust...   \n",
       "1     [push, young, texas, experiment, nothing, conc...   \n",
       "2     [nt, be, allowed, know, want, who, someone, su...   \n",
       "3     [communist, forcefully, okay, people, brutal, ...   \n",
       "4     [alive, also, creation, death, proteins, body,...   \n",
       "...                                                 ...   \n",
       "3995  [will, double, receive, police, australia, apa...   \n",
       "3996  [also, filled, know, off, unchecked, may, deep...   \n",
       "3997  [own, health, recorded, know, road, can, europ...   \n",
       "3998  [rollout, vaccination, inexplicable, thank, bi...   \n",
       "3999  [page, self, know, foot, need, deep, psyche, a...   \n",
       "\n",
       "                              top_3_emotions  max_emotion  \n",
       "0            [inspiration, amusement, anger]  inspiration  \n",
       "1             [inspiration, amusement, fear]  inspiration  \n",
       "2     [inspiration, indifference, amusement]  inspiration  \n",
       "3            [anger, annoyance, inspiration]        anger  \n",
       "4             [inspiration, amusement, fear]  inspiration  \n",
       "...                                      ...          ...  \n",
       "3995           [anger, inspiration, sadness]        anger  \n",
       "3996     [inspiration, amusement, annoyance]  inspiration  \n",
       "3997     [annoyance, amusement, inspiration]    annoyance  \n",
       "3998  [inspiration, amusement, indifference]  inspiration  \n",
       "3999     [inspiration, amusement, annoyance]  inspiration  \n",
       "\n",
       "[4000 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b559f-a4eb-476e-a807-168a781a16ac",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c9bbb37-90fd-4abb-81ff-6316d7ae2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/train/dataset_en_train_with_emotions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fed005-949b-4634-a880-9b49f134f842",
   "metadata": {},
   "source": [
    "# Emotion Spanish Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82644ec5-a91a-42be-a8b7-86aeaa59e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pysentimiento/pysentimiento , https://pypi.org/project/pysentimiento/0.5.2rc3/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f85c67c-e284-482d-8f55-cb6779e986a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pysentimiento import create_analyzer\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/train/dataset_es_train_augmented.csv\")\n",
    "df\n",
    "\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "\n",
    "\n",
    "def get_sentiment(text):\n",
    "    # Obtener el resultado de la predicción\n",
    "    result = analyzer.predict(text)\n",
    "    # El sentimiento predicho es POS, NEG, o NEU\n",
    "    return result.output\n",
    "\n",
    "# Aplicar la función a la columna 'text' del DataFrame\n",
    "df['sentiment'] = df['text'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f31e83b4-1f94-4a68-bf01-ba0c282e84f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/train/dataset_es_train_with_sentiment.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "385a0520-3a66-4654-8b4c-d6eb475c7cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>annotations</th>\n",
       "      <th>spacy_tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2807</td>\n",
       "      <td>fallo en matrix hoy el señor joan ramón laport...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'el señor Joan Ramón Laporte Ro...</td>\n",
       "      <td>WyJGYWxsbyIsICJlbiIsICJNYXRyaXgiLCAiMDgvMDIvMj...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3054</td>\n",
       "      <td>siento ya tdas las vacunas vienen contaminadas...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': 'mi sobrina', 'category': 'VICT...</td>\n",
       "      <td>WyJTaWVudG8iLCAieWEiLCAidGRhcyIsICJsYXMiLCAidm...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>veo que curiosamente te autoproclamados interl...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>[{'span_text': 'todo el grupo', 'category': 'C...</td>\n",
       "      <td>WyJWZW8iLCAicXVlIiwgImN1cmlvc2FtZW50ZSIsICJ0ZS...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2669</td>\n",
       "      <td>documental vacunas una inyección en la oscurid...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>[{'span_text': '[ Documental ] Vacunas : Una i...</td>\n",
       "      <td>WyJbIiwgIkRvY3VtZW50YWwiLCAiXSIsICJWYWN1bmFzIi...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3205</td>\n",
       "      <td>una sugerencia para los que se han vacunado y ...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>[{'span_text': 'los que se han vacunado y no q...</td>\n",
       "      <td>WyJVbmEiLCAic3VnZXJlbmNpYSIsICJwYXJhIiwgImxvcy...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>mr5w0</td>\n",
       "      <td>Dr. Robert Malone . co inventor de la tecnolog...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>uYwCK</td>\n",
       "      <td>una pregunta la vacuna también causa hipotiroi...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>CFz4d</td>\n",
       "      <td>Eric Clapton el famoso guitarrista cuenta cómo...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>JstSN</td>\n",
       "      <td>No es un médico, no es un científico, no es un...</td>\n",
       "      <td>CONSPIRACY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>edsVF</td>\n",
       "      <td>Hola, traigo la prueba de curación de mi padre...</td>\n",
       "      <td>CRITICAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text    category  \\\n",
       "0      2807  fallo en matrix hoy el señor joan ramón laport...    CRITICAL   \n",
       "1      3054  siento ya tdas las vacunas vienen contaminadas...    CRITICAL   \n",
       "2       268  veo que curiosamente te autoproclamados interl...  CONSPIRACY   \n",
       "3      2669  documental vacunas una inyección en la oscurid...    CRITICAL   \n",
       "4      3205  una sugerencia para los que se han vacunado y ...  CONSPIRACY   \n",
       "...     ...                                                ...         ...   \n",
       "7995  mr5w0  Dr. Robert Malone . co inventor de la tecnolog...    CRITICAL   \n",
       "7996  uYwCK  una pregunta la vacuna también causa hipotiroi...    CRITICAL   \n",
       "7997  CFz4d  Eric Clapton el famoso guitarrista cuenta cómo...    CRITICAL   \n",
       "7998  JstSN  No es un médico, no es un científico, no es un...  CONSPIRACY   \n",
       "7999  edsVF  Hola, traigo la prueba de curación de mi padre...    CRITICAL   \n",
       "\n",
       "                                            annotations  \\\n",
       "0     [{'span_text': 'el señor Joan Ramón Laporte Ro...   \n",
       "1     [{'span_text': 'mi sobrina', 'category': 'VICT...   \n",
       "2     [{'span_text': 'todo el grupo', 'category': 'C...   \n",
       "3     [{'span_text': '[ Documental ] Vacunas : Una i...   \n",
       "4     [{'span_text': 'los que se han vacunado y no q...   \n",
       "...                                                 ...   \n",
       "7995                                                NaN   \n",
       "7996                                                NaN   \n",
       "7997                                                NaN   \n",
       "7998                                                NaN   \n",
       "7999                                                NaN   \n",
       "\n",
       "                                           spacy_tokens sentiment  \n",
       "0     WyJGYWxsbyIsICJlbiIsICJNYXRyaXgiLCAiMDgvMDIvMj...       NEG  \n",
       "1     WyJTaWVudG8iLCAieWEiLCAidGRhcyIsICJsYXMiLCAidm...       NEG  \n",
       "2     WyJWZW8iLCAicXVlIiwgImN1cmlvc2FtZW50ZSIsICJ0ZS...       NEG  \n",
       "3     WyJbIiwgIkRvY3VtZW50YWwiLCAiXSIsICJWYWN1bmFzIi...       NEU  \n",
       "4     WyJVbmEiLCAic3VnZXJlbmNpYSIsICJwYXJhIiwgImxvcy...       POS  \n",
       "...                                                 ...       ...  \n",
       "7995                                                NaN       NEG  \n",
       "7996                                                NaN       NEG  \n",
       "7997                                                NaN       NEU  \n",
       "7998                                                NaN       NEG  \n",
       "7999                                                NaN       NEU  \n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/train/dataset_es_train_with_sentiment.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
