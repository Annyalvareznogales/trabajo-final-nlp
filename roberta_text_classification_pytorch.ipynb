{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzM1_ykHaFur"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "from transformers import RobertaTokenizer, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLxxwd1scQNv"
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCaDM5rkmsf9"
   },
   "source": [
    "# Datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1732006247385,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "mZ7lTlkyaG7u",
    "outputId": "19435ba3-6504-40b9-9dc7-86d8529e28ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRITICAL</th>\n",
       "      <td>2621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONSPIRACY</th>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "category\n",
       "CRITICAL      2621\n",
       "CONSPIRACY    1379\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_en_train_completed.csv')\n",
    "df=df.iloc[:4000,:]\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rinAOGUjmsf-"
   },
   "source": [
    "# Datos balanceados (Aumento de Datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GhxP1owmsf_"
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/train/dataset_en_train_completed.csv')\n",
    "df= df.iloc[:4000]\n",
    "\n",
    "df_augmented= pd.read_csv('data/train/dataset_en_train_completed.csv')\n",
    "df_augmented= df_augmented.iloc[4000:]\n",
    "#df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4K5aVHFmsgA"
   },
   "outputs": [],
   "source": [
    "original_counts = df['category'].value_counts()\n",
    "df_conspiracy = df[df['category'] == 'CONSPIRACY']\n",
    "df_conspiracy_augmented = df_augmented[df_augmented['category'] == 'CONSPIRACY']\n",
    "critical_count = original_counts.get('CRITICAL', 0) \n",
    "conspiracy_count = original_counts.get('CONSPIRACY', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZNTqKKsmsgA"
   },
   "outputs": [],
   "source": [
    "df_conspiracy = df_augmented[df_augmented['category'] == 'CONSPIRACY']\n",
    "\n",
    "# Seleccionar 1242 filas aleatorias para balancear el dataset \n",
    "df_conspiracy_sampled = df_conspiracy.sample(n=1242, random_state=42)\n",
    "df_combined = pd.concat([df, df_conspiracy_sampled])\n",
    "\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "df=df_combined.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de Prompts (emoción y moralidad reflejada en texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQKfvpCFmsgB",
    "outputId": "9b6ac026-77e5-442e-898a-bb3ef3725465"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how the cia is directly involved in every aspect of the creation of the vaccine passports . groups created by the cia like palantir , mitre , oracle , and google , funded through the cias venture capital firm , in q tel , are are involved . every one of them are listed on the organizational member lists of the private companies in charge of the creation of all worldwide passports . full article . dailyveracity . com the shadowy cia data firms behind the creation of digital vaccine passport ids full video . bitchute . com video ufysjysoe donna. The text reflects the emotion: inspiration and the moral value loyalty'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_context(df):\n",
    "    # Añade información contextual usando corchetes\n",
    "    df['text'] =   df['text'] + '. The text reflects the emotion: ' + df['max_emotion'] + ' and the moral value: ' + df['max_moral']\n",
    "    return df\n",
    "\n",
    "\n",
    "df=add_context(df)\n",
    "df.loc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B39VMmbEmsgC"
   },
   "source": [
    "# Transformar etiqueta de categórica a numérica\n",
    "\n",
    "Critical = 1\n",
    "Conspirancy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixRQy14FmsgC",
    "outputId": "8eb05aa2-0098-4cae-96ea-c21d856e8339"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how the cia is directly involved in every aspe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elon musk admits i felt like i was dying after...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the uk gov. quietly published data confirming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the global economic terror regime, which is lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>confirmed pharma fags crashed into a covid vac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>coming soon doctors for covid ethics fourth sy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>the vaccine mandates as i said last year have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>Minority report in real life a group of social...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>This is the reason why the Cabal does not want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>did you know the cdc is actually a vaccine com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  class\n",
       "0     how the cia is directly involved in every aspe...      0\n",
       "1     elon musk admits i felt like i was dying after...      1\n",
       "2     the uk gov. quietly published data confirming ...      1\n",
       "3     the global economic terror regime, which is lo...      0\n",
       "4     confirmed pharma fags crashed into a covid vac...      1\n",
       "...                                                 ...    ...\n",
       "5237  coming soon doctors for covid ethics fourth sy...      1\n",
       "5238  the vaccine mandates as i said last year have ...      1\n",
       "5239  Minority report in real life a group of social...      0\n",
       "5240  This is the reason why the Cabal does not want...      0\n",
       "5241  did you know the cdc is actually a vaccine com...      1\n",
       "\n",
       "[5242 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "\n",
    "new_df = df[['text', 'class']].copy()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqveDcmDeVrZ"
   },
   "source": [
    "# Parámetros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikfbFlNHgi8T"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFOylAXqiNYK"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe['text']\n",
    "        self.targets = self.data['class']\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        # Tokenize the text\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        ids = inputs['input_ids'].squeeze()\n",
    "        mask = inputs['attention_mask'].squeeze()\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': ids,\n",
    "            'mask': mask,\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8Z3O2tFeVrb"
   },
   "source": [
    "# Modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizaron diferentes implementaciones con Roberta base y Roberta large evaluando los resultados obtenidos al añadir los prompts y el aumento de datos. Por limitaciones de recursos computacionales, se ejecutó una vez el modelo de Roberta-Large, el cual se queda reflejado en este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830,
     "referenced_widgets": [
      "42195991074a4eb78247eecbdd0bd834",
      "c40e2d6629054e1fae9f506aae6db45a",
      "f0a1943bc20b427f97a4068aeb50d8d8",
      "e2d4b0a3ba474a47b4002571bc5f7e46",
      "84203a1a076349a3bde070cbda900601",
      "835049488c554ae2b05852b194b1ed9c",
      "d10a65de80304fa79b2e55e7bdc0d481",
      "3ba62a7dbd884db9a26c4e717d46ce9a",
      "2daf145267054614a40293de36d69f80",
      "bad21d3465fd4801acef250dcc7dbc82",
      "f3b84121f23344d29477fcf5e546f9bd"
     ]
    },
    "executionInfo": {
     "elapsed": 3486,
     "status": "ok",
     "timestamp": 1730571562136,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "DegHNyIEQxB2",
    "outputId": "c0f47e1c-46f0-44db-8c74-8fd8b3688efd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RoBERTaClass(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RoBERTaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RoBERTaClass, self).__init__()\n",
    "        self.l1 = transformers.RobertaModel.from_pretrained('roberta-large')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        #1 es porque en este caso es una  tarea binaria\n",
    "        self.l3 = torch.nn.Linear(1024, 1)  #1024 para roberta-large\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2).squeeze(1)\n",
    "        return output\n",
    "\n",
    "model = RoBERTaClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KnNeQx6SI78"
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUD8j0c7WsA-"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW9UZ-l8msgI"
   },
   "source": [
    "# Fine Tuning (Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCj3VeoUAMy4"
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader):\n",
    "    model.train()  \n",
    "    for _, data in enumerate(train_loader):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()  # Limpiar los gradientes previos\n",
    "        outputs = model(ids, mask)  # Propagación hacia adelante\n",
    "        loss = loss_fn(outputs, targets) \n",
    "\n",
    "        if _ % 5000 == 0: \n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "        loss.backward()  # Propagación hacia atrás\n",
    "        optimizer.step()  # Actualizar los pesos del modelo\n",
    "\n",
    "def validation(model, data_loader, device):\n",
    "    model.eval()  \n",
    "    fin_targets = []  # etiquetas verdaderas\n",
    "    fin_outputs = []  # probabilidades de las predicciones\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for data in data_loader:\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            outputs = model(ids, mask) \n",
    "            outputs = torch.sigmoid(outputs)\n",
    "\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    return fin_outputs, fin_targets\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate_metrics(outputs, targets):\n",
    "    # Convertir las salidas a 0 o 1 (clases predichas) basadas en el umbral 0.5\n",
    "    outputs = [1 if x > 0.5 else 0 for x in outputs]\n",
    "\n",
    "    # Calcular las métricas\n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(targets, outputs, average='binary')\n",
    "    mcc = matthews_corrcoef(targets, outputs)  # Calcular MCC\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc\n",
    "    }\n",
    "    # Imprimir los resultados\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "\n",
    "\n",
    "def cross_validate_model(model, dataframe, tokenizer,title, epochs=3, batch_size=16, k_folds=5):\n",
    "    #kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    #skfold es mejor opción cuando se tiene desbalanceo de datos\n",
    "    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    metrics_list = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataframe, dataframe['class'])):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "        train_df = dataframe.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = dataframe.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        train_set = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "        val_set = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train(epoch, model, train_loader)  \n",
    "\n",
    "        outputs, targets = validation(model, val_loader, device)\n",
    "        fold_metrics=evaluate_metrics(outputs, targets)\n",
    "        metrics_list.append(fold_metrics)\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "    # Guardar el DataFrame en un archivo CSV\n",
    "    metrics_df.to_csv(f'metrics{title}.csv', index=False)\n",
    "\n",
    "    print('Cross-validation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjH9wsfkAPwB",
    "outputId": "713a4a84-fae3-405a-f9c7-37bc9fcacf58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Epoch: 0, Loss: 0.7348228096961975\n",
      "Epoch: 1, Loss: 0.4871571660041809\n",
      "Epoch: 2, Loss: 0.018146932125091553\n",
      "\n",
      "Fold 2/5\n",
      "Epoch: 0, Loss: 0.007466912269592285\n",
      "Epoch: 1, Loss: 0.008322915062308311\n",
      "Epoch: 2, Loss: 0.0579494945704937\n",
      "\n",
      "Fold 3/5\n",
      "Epoch: 0, Loss: 0.003274182789027691\n",
      "Epoch: 1, Loss: 0.0032785036601126194\n",
      "Epoch: 2, Loss: 0.0026664207689464092\n",
      "\n",
      "Fold 4/5\n",
      "Epoch: 0, Loss: 0.008489318192005157\n",
      "Epoch: 1, Loss: 0.004815469030290842\n",
      "Epoch: 2, Loss: 0.0007440482149831951\n",
      "\n",
      "Fold 5/5\n",
      "Epoch: 0, Loss: 0.00466996431350708\n",
      "Epoch: 1, Loss: 0.004115194547921419\n",
      "Epoch: 2, Loss: 0.001830673310905695\n",
      "Cross-validation complete\n"
     ]
    }
   ],
   "source": [
    "# cambiar nombre de archivo que se guarda\n",
    "cross_validate_model(model, new_df, tokenizer, 'moral_emo_512_8_2e5_rl_skfold_augmented',epochs=3, batch_size=TRAIN_BATCH_SIZE, k_folds=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbQB5e2-eVre"
   },
   "source": [
    "# Guardar Modelo Ajustado (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbRCa-DgtmOe"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"roberta_large_finetuned_model_en.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bYVOWinuxg6"
   },
   "source": [
    "# Cargar Modelo ajustado (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2989,
     "status": "ok",
     "timestamp": 1730569245723,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "WdgvYxwBuxzM",
    "outputId": "be13b073-b546-4f0a-d382-f415b0aa2a9a"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "MODEL_PATH = \"./model/roberta_large_finetuned_model_en.pth\"\n",
    "\n",
    "loaded_model = RoBERTaClass()\n",
    "loaded_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXrZVs7VuPyU"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1730569342132,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "GUnpQCwytmRR",
    "outputId": "8a5d698a-c2dd-4f8a-ba8a-4a9e19fcd156"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elon now confirming what we ve been suspecting...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keeping the pressure on the police to uphold t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe effective the greatest lie ever told . th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdc report admits . million people in the usa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how to use health to acquire totalitarian cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>john d. rockefeller wiped out natural cures to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>fact check biden white house falsely accuses d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>w onset acral hand lesions following mrna vacc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>we will fire unvaccinated workers cohen hadad ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>they are gearing up for the booster kill shot ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  class\n",
       "0    elon now confirming what we ve been suspecting...      0\n",
       "1    keeping the pressure on the police to uphold t...      0\n",
       "2    safe effective the greatest lie ever told . th...      1\n",
       "3    cdc report admits . million people in the usa ...      1\n",
       "4    how to use health to acquire totalitarian cont...      0\n",
       "..                                                 ...    ...\n",
       "995  john d. rockefeller wiped out natural cures to...      0\n",
       "996  fact check biden white house falsely accuses d...      1\n",
       "997  w onset acral hand lesions following mrna vacc...      1\n",
       "998  we will fire unvaccinated workers cohen hadad ...      1\n",
       "999  they are gearing up for the booster kill shot ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"data/test/dataset_en_test_cleaned.csv\")\n",
    "test_df['class'] = test_df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "test_df = test_df[['text', 'class']].copy()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3M7c-GJjmsgO",
    "outputId": "851823ab-4711-48f0-fb41-323eefce949e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results saved to test_evaluation_results_512_2e5_moral_emotions_robertalarge_skfold_augmented.json\n",
      "Test MCC = 0.8244584282457748\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "def predict(text, model, tokenizer):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    ids = inputs['input_ids'].to(device)\n",
    "    mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(ids, mask)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        prediction = 1 if probabilities[0] >= 0.5 else 0\n",
    "\n",
    "    return prediction, probabilities[0]\n",
    "\n",
    "\n",
    "def test_and_evaluate(model, tokenizer, test_df, filename=\"test_results.json\"):\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        text = row['text']\n",
    "        prediction, probability = predict(text, model, tokenizer)  \n",
    "        predictions.append(prediction)\n",
    "        probabilities.append(probability)\n",
    "\n",
    "    test_df['predictions'] = predictions\n",
    "    test_df['probabilities'] = probabilities\n",
    "\n",
    "    mcc = matthews_corrcoef(test_df['class'], test_df['predictions'])\n",
    "    results = classification_report(\n",
    "        test_df['class'],\n",
    "        test_df['predictions'],\n",
    "        target_names=['CONSPIRANCY', 'CRITICAL'], \n",
    "        digits=5,\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    output_data = {\n",
    "        \"mcc\": mcc,\n",
    "        \"classification_report\": results\n",
    "    }\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "    print(f\"Test results saved to {filename}\")\n",
    "    print(f\"Test MCC = {mcc}\")\n",
    "\n",
    "# Example usage:\n",
    "test_and_evaluate(model, tokenizer, test_df, filename=\"test_evaluation_results_512_2e5_moral_emotions_robertalarge_skfold_augmented.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TatHpXamsgP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1MlYXhBkYvnDDxcjwBI9dcnzHDC8YhlRY",
     "timestamp": 1732006303116
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2daf145267054614a40293de36d69f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ba62a7dbd884db9a26c4e717d46ce9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42195991074a4eb78247eecbdd0bd834": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c40e2d6629054e1fae9f506aae6db45a",
       "IPY_MODEL_f0a1943bc20b427f97a4068aeb50d8d8",
       "IPY_MODEL_e2d4b0a3ba474a47b4002571bc5f7e46"
      ],
      "layout": "IPY_MODEL_84203a1a076349a3bde070cbda900601"
     }
    },
    "835049488c554ae2b05852b194b1ed9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84203a1a076349a3bde070cbda900601": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bad21d3465fd4801acef250dcc7dbc82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c40e2d6629054e1fae9f506aae6db45a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_835049488c554ae2b05852b194b1ed9c",
      "placeholder": "​",
      "style": "IPY_MODEL_d10a65de80304fa79b2e55e7bdc0d481",
      "value": "model.safetensors: 100%"
     }
    },
    "d10a65de80304fa79b2e55e7bdc0d481": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2d4b0a3ba474a47b4002571bc5f7e46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bad21d3465fd4801acef250dcc7dbc82",
      "placeholder": "​",
      "style": "IPY_MODEL_f3b84121f23344d29477fcf5e546f9bd",
      "value": " 440M/440M [00:02&lt;00:00, 187MB/s]"
     }
    },
    "f0a1943bc20b427f97a4068aeb50d8d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ba62a7dbd884db9a26c4e717d46ce9a",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2daf145267054614a40293de36d69f80",
      "value": 440449768
     }
    },
    "f3b84121f23344d29477fcf5e546f9bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
