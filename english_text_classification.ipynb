{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b3722-f4aa-4ad1-8f5a-c67577a722dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import transformers\n",
    "import ast\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, RobertaTokenizer, RobertaModel\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f25d6-7b71-4914-832d-bac1f28afcbb",
   "metadata": {},
   "source": [
    "Para la tarea de clasificación en inglés, nos enfocamos en estrategias de enriquecimiento de datos, aprovechando las capacidades de autoatención de los modelos transformers, utilizando exclusivamente los encoders de arquitecturas como BERT y RoBERTa.\n",
    "\n",
    "Preprocesamiento de Datos:\n",
    "Se limpiaron los conjuntos de entrenamiento y prueba eliminando elementos como URLs para facilitar la interpretación correcta de los textos.\n",
    "Este preprocesamiento se aplicó tanto a datos en inglés como en español, asegurando consistencia en ambos conjuntos.\n",
    "Manejo del Desequilibrio de Clases:\n",
    "Se identificó un desequilibrio significativo en los datos, con una clara subrepresentación de la clase CONSPIRACY.\n",
    "Para abordar este problema, se implementó una estrategia de oversampling, pero con un enfoque diferenciador: los textos originales fueron traducidos a otro idioma utilizando modelos preentrenados de Hugging Face y luego traducidos de vuelta al idioma original. Esta técnica generó datos similares pero no idénticos, mitigando riesgos de overfitting.\n",
    "Adición de Información Contextual:\n",
    "Dada la subjetividad de la tarea, se exploraron estrategias para enriquecer los datos con información adicional. Inicialmente, se consideró utilizar modelos preentrenados para extraer características textuales como emociones, pero esta opción se descartó debido a su dependencia del sesgo del modelo seleccionado.\n",
    "Optamos por incorporar léxicos en inglés (emocionales y morales) que relacionan palabras clave en los textos con emociones y valores morales. La información extraída de estos léxicos se incluyó como un prompt añadido al final del texto original, indicando qué emoción y valor moral reflejaba el contenido.\n",
    "Experimentos y Ajustes:\n",
    "Se realizaron múltiples experimentos para identificar el modelo preentrenado más efectivo (comparando entre BERT base uncased y RoBERTa), evaluar el impacto del aumento de datos y ajustar hiperparámetros clave.\n",
    "También se exploraron configuraciones avanzadas, como el aumento del tamaño de batch, para mejorar los resultados del modelo.\n",
    "Resultados y Métricas:\n",
    "Los resultados fueron evaluados utilizando métricas como F1-score macro y micro, y el coeficiente MCC, según lo solicitado en la competencia original.\n",
    "El mejor desempeño se obtuvo con el modelo RoBERTa, en combinación con el aumento de datos mediante traducciones y la adición del contexto emocional y moral extraído de los léxicos. Este enfoque superó el baseline de la competencia PAN.\n",
    "Experimentación Adicional:\n",
    "Como parte de la exploración de técnicas avanzadas, modificamos la estructura base de RoBERTa añadiendo capas de atención múltiple y convoluciones, (siguiendo un enfoque basado en el paper Cheruku, R. et al. (2023) Sentiment classification with modified Roberta and recurrent neural networks - multimedia tools and applications, SpringerLink. Available at: https://link.springer.com/article/10.1007/s11042-023-16833-5 (Accessed: 22 November 2024) . Aunque no se lograron mejoras significativas, este experimento permitió aprender cómo alterar arquitecturas para tareas con alta subjetividad, como clasificar emociones y añadir metadatos textuales.\n",
    "También se realizó un experimento combinando las representaciones [CLS] de BERT y RoBERTa. Los embeddings de ambas arquitecturas (768 dimensiones cada uno) fueron concatenados para formar un vector de 1536 dimensiones, que se introdujo en una capa totalmente conectada para la clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d3c9a-0f25-4cb2-b68c-99387e9ab4be",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe64df8b-ae05-4b74-b57b-d140ca7b593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train/dataset_en_train_completed.csv')\n",
    "df-value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce210bc5-3260-49a1-9556-4f65542ca150",
   "metadata": {},
   "source": [
    "# Datos Aumentados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc35fc1-a4d4-488f-99d8-83d2d531516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/train/dataset_en_train_completed.csv')\n",
    "df= df.iloc[:4000]\n",
    "\n",
    "df_augmented= pd.read_csv('data/train/dataset_en_train_completed.csv')\n",
    "df_augmented= df_augmented.iloc[4000:]\n",
    "df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692e4d2-5658-4d59-82dc-2b127e2a8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_counts = df['category'].value_counts()\n",
    "df_conspiracy = df[df['category'] == 'CONSPIRACY']\n",
    "df_conspiracy_augmented = df_augmented[df_augmented['category'] == 'CONSPIRACY']\n",
    "critical_count = original_counts.get('CRITICAL', 0)  \n",
    "conspiracy_count = original_counts.get('CONSPIRACY', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645ab16-1ca3-4931-8cf4-ddf25a7b429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conspiracy = df_augmented[df_augmented['category'] == 'CONSPIRACY']\n",
    "\n",
    "# Seleccionar 1242 filas aleatorias para balancear el dataset \n",
    "df_conspiracy_sampled = df_conspiracy.sample(n=1242, random_state=42)\n",
    "df_combined = pd.concat([df, df_conspiracy_sampled])\n",
    "\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "df=df_combined.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e58b10-7ff5-4015-8e0f-f9d285e3b7bf",
   "metadata": {},
   "source": [
    "# Añadir información del texto (emoción y moral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494f646-b64e-43c9-81bf-486cad1a0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_context(df):\n",
    "    df['text'] =   df['text'] + '. The text reflects the emotion: ' + df['max_emotion'] + ' and the moral value: ' + df['max_moral'] \n",
    "    return df\n",
    "\n",
    "df=add_context(df)\n",
    "df.loc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe00cd-6b9e-4d81-9daf-3c3782e28824",
   "metadata": {},
   "source": [
    "# Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f28cf-f743-42a4-8110-20bbfe405443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificados en función del experimento realizado\n",
    "#Bert\n",
    "MAX_LEN = 512 \n",
    "TRAIN_BATCH_SIZE = 32 \n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 3 \n",
    "LEARNING_RATE = 2e-5 \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Roberta\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "# Roberta Modificada\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb77e9b-74f0-41ef-9d28-c879d0d3a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar etiquetas de categóricas a numéricas\n",
    "#Critical = 1 Conspirancy = 0\n",
    "df['class'] = df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "\n",
    "new_df = df[['text', 'class']].copy()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6157075-b3a6-41c2-9c7e-57b387af87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7502ada-8b29-4580-b724-7c009dd31a71",
   "metadata": {},
   "source": [
    "# DataLoaders y Modelos Para los Diferentes Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75e644-3745-4a54-a48e-292074a1dcb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Experimentos Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc3d48-bd48-47cf-a235-ce79745cab15",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cabdd52-6e03-4b4c-a3f2-dc1bab344096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe['text']\n",
    "        self.targets = self.data['class']\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        # Tokenize the text\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        ids = inputs['input_ids'].squeeze()\n",
    "        mask = inputs['attention_mask'].squeeze()\n",
    "        token_type_ids = inputs[\"token_type_ids\"].squeeze()\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': ids,\n",
    "            'mask': mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        #1 es porque en este caso es una  tarea binaria\n",
    "        self.l3 = torch.nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2).squeeze(1)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fada1b5-41e4-4bcd-b2e8-bd4af023a879",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61bf9e-23bb-4336-986c-ce377faf938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader):\n",
    "    model.train()  # Poner el modelo en modo de entrenamiento\n",
    "    for _, data in enumerate(train_loader):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()  # Limpiar los gradientes previos\n",
    "        outputs = model(ids, mask, token_type_ids)  \n",
    "        loss = loss_fn(outputs, targets)  # pérdida\n",
    "\n",
    "        if _ % 5000 == 0:  \n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "def validation(model, data_loader, device):\n",
    "    model.eval()  \n",
    "    fin_targets = []  # etiqueta verdadera\n",
    "    fin_outputs = []  # predicciones\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for data in data_loader:\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            token_type_ids = data['token_type_ids'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            # Get model outputs\n",
    "            outputs = model(ids, mask, token_type_ids)  \n",
    "            # funcion sigmoide para la salida como probabilidades\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    return fin_outputs, fin_targets\n",
    "\n",
    "\n",
    "    # Convertir las salidas a 0 o 1 (clases predichas) basadas en el umbral 0.5\n",
    "    outputs = [1 if x > 0.5 else 0 for x in outputs]\n",
    "\n",
    "    # Calcular las métricas\n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(targets, outputs, average='binary')\n",
    "    mcc = matthews_corrcoef(targets, outputs)  # Calcular MCC\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc\n",
    "    }\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "\n",
    "def cross_validate_model(model, dataframe, tokenizer,title, epochs=3, batch_size=16, k_folds=5):\n",
    "    #kfold\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    metrics_list = [] \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataframe)):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "        train_df = dataframe.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = dataframe.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        # Dividir datos en entrenamiento y validación\n",
    "        train_set = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "        val_set = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Se entrena para cada fold\n",
    "        for epoch in range(epochs):\n",
    "            train(epoch, model, train_loader)  \n",
    "\n",
    "        # Se valida\n",
    "        outputs, targets = validation(model, val_loader, device)\n",
    "        \n",
    "        fold_metrics=evaluate_metrics(outputs, targets) \n",
    "        metrics_list.append(fold_metrics)\n",
    "        \n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "    # Se guardan las métricas del entreno\n",
    "    metrics_df.to_csv(f'metrics{title}.csv', index=False)\n",
    "\n",
    "    print('Cross-validation complete')\n",
    "\n",
    "# Cambiar el nombre del archivo que se guarda\n",
    "cross_validate_model(model, new_df, tokenizer, 'moral_emotions_512_32_2e5_bbu', epochs=3, batch_size=TRAIN_BATCH_SIZE, k_folds=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98384f0-cf8c-4e4f-abc3-eeee65ef745c",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59709c17-95d5-4979-be41-10d6e03843fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/test/dataset_en_test_cleaned.csv\")\n",
    "test_df['class'] = test_df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "test_df = test_df[['text', 'class']].copy()\n",
    "test_df\n",
    "\n",
    "model.eval()\n",
    "\n",
    "#usar modelo y tokenizer\n",
    "def predict(text, model, tokenizer):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    ids = inputs['input_ids'].to(device)\n",
    "    mask = inputs['attention_mask'].to(device)\n",
    "    token_type_ids = inputs['token_type_ids'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(ids, mask, token_type_ids) \n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        prediction = 1 if probabilities[0] >= 0.5 else 0\n",
    "\n",
    "    return prediction, probabilities[0]\n",
    "\n",
    "def test_and_evaluate(model, tokenizer, test_df, filename=\"test_results.json\"):\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    for index, row in test_df.iterrows():\n",
    "        text = row['text']\n",
    "        prediction, probability = predict(text, model, tokenizer) \n",
    "        predictions.append(prediction)\n",
    "        probabilities.append(probability)\n",
    "\n",
    "    test_df['predictions'] = predictions\n",
    "    test_df['probabilities'] = probabilities\n",
    "    mcc = matthews_corrcoef(test_df['class'], test_df['predictions'])\n",
    "    results = classification_report(\n",
    "        test_df['class'], \n",
    "        test_df['predictions'], \n",
    "        target_names=['CONSPIRANCY', 'CRITICAL'],  \n",
    "        digits=5, \n",
    "        output_dict=True)\n",
    "\n",
    "    # Guardar\n",
    "    output_data = {\n",
    "        \"mcc\": mcc,\n",
    "        \"classification_report\": results}\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "    print(f\"Test results saved to {filename}\")\n",
    "    print(f\"Test MCC = {mcc}\")\n",
    "\n",
    "#Cambiar nombre de fichero con métricas\n",
    "test_and_evaluate(model, tokenizer, test_df, filename=\"test_evaluation_results_512_2e5_emotions_morals.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16957a83-7eec-42ef-b0ab-a0713463b2a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Experimentos Roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c023261c-81e6-40a5-b097-4dccab760a6d",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97dcc4-b874-4959-a540-d3cd3ba73ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe['text']\n",
    "        self.targets = self.data['class']\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "\n",
    "        ids = inputs['input_ids'].squeeze()\n",
    "        mask = inputs['attention_mask'].squeeze()\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': ids,\n",
    "            'mask': mask,\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class RoBERTaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RoBERTaClass, self).__init__()\n",
    "        self.l1 = transformers.RobertaModel.from_pretrained('roberta-large')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        #1 es porque en este caso es una  tarea binaria\n",
    "        self.l3 = torch.nn.Linear(1024, 1)  #1024 para roberta-large\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2).squeeze(1)\n",
    "        return output\n",
    "\n",
    "model = RoBERTaClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392fe78-0be4-4bd8-9a52-0e5b71c483de",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e121f7e-b293-493d-83d0-87273db7778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader):\n",
    "    model.train()  \n",
    "    for _, data in enumerate(train_loader):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()  # Limpiar los gradientes previos\n",
    "        outputs = model(ids, mask)  # Propagación hacia adelante\n",
    "        loss = loss_fn(outputs, targets) \n",
    "\n",
    "        if _ % 5000 == 0: \n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "        loss.backward()  # Propagación hacia atrás\n",
    "        optimizer.step()  # Actualizar los pesos del modelo\n",
    "\n",
    "def validation(model, data_loader, device):\n",
    "    model.eval()  \n",
    "    fin_targets = []  # etiquetas verdaderas\n",
    "    fin_outputs = []  # probabilidades de las predicciones\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for data in data_loader:\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            outputs = model(ids, mask) \n",
    "            outputs = torch.sigmoid(outputs)\n",
    "\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    return fin_outputs, fin_targets\n",
    "    \n",
    "def evaluate_metrics(outputs, targets):\n",
    "    # Convertir las salidas a 0 o 1 (clases predichas) basadas en el umbral 0.5\n",
    "    outputs = [1 if x > 0.5 else 0 for x in outputs]\n",
    "\n",
    "    # Calcular las métricas\n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(targets, outputs, average='binary')\n",
    "    mcc = matthews_corrcoef(targets, outputs)  # Calcular MCC\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc\n",
    "    }\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "\n",
    "\n",
    "def cross_validate_model(model, dataframe, tokenizer,title, epochs=3, batch_size=16, k_folds=5):\n",
    "    #kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    #skfold es mejor opción cuando se tiene desbalanceo de datos\n",
    "    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    metrics_list = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataframe, dataframe['class'])):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "        train_df = dataframe.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = dataframe.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        train_set = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "        val_set = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train(epoch, model, train_loader)  \n",
    "\n",
    "        outputs, targets = validation(model, val_loader, device)\n",
    "        fold_metrics=evaluate_metrics(outputs, targets)\n",
    "        metrics_list.append(fold_metrics)\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "    metrics_df.to_csv(f'metrics{title}.csv', index=False)\n",
    "\n",
    "    print('Cross-validation complete')\n",
    "\n",
    "# cambiar nombre de archivo que se guarda\n",
    "cross_validate_model(model, new_df, tokenizer, 'moral_emo_512_8_2e5_rl_skfold_augmented',epochs=3, batch_size=TRAIN_BATCH_SIZE, k_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8244d4-f77b-4743-8dc1-26a0862328c6",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d05fe-360c-4e7f-96ff-074d1aeb8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/test/dataset_en_test_cleaned.csv\")\n",
    "test_df['class'] = test_df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "test_df = test_df[['text', 'class']].copy()\n",
    "test_df\n",
    "\n",
    "model.eval()\n",
    "def predict(text, model, tokenizer):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    ids = inputs['input_ids'].to(device)\n",
    "    mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(ids, mask)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        prediction = 1 if probabilities[0] >= 0.5 else 0\n",
    "\n",
    "    return prediction, probabilities[0]\n",
    "\n",
    "def test_and_evaluate(model, tokenizer, test_df, filename=\"test_results.json\"):\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        text = row['text']\n",
    "        prediction, probability = predict(text, model, tokenizer)  \n",
    "        predictions.append(prediction)\n",
    "        probabilities.append(probability)\n",
    "\n",
    "    test_df['predictions'] = predictions\n",
    "    test_df['probabilities'] = probabilities\n",
    "\n",
    "    mcc = matthews_corrcoef(test_df['class'], test_df['predictions'])\n",
    "    results = classification_report(\n",
    "        test_df['class'],\n",
    "        test_df['predictions'],\n",
    "        target_names=['CONSPIRANCY', 'CRITICAL'], \n",
    "        digits=5,\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    output_data = {\n",
    "        \"mcc\": mcc,\n",
    "        \"classification_report\": results\n",
    "    }\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "    print(f\"Test results saved to {filename}\")\n",
    "    print(f\"Test MCC = {mcc}\")\n",
    "\n",
    "test_and_evaluate(model, tokenizer, test_df, filename=\"test_evaluation_results_512_2e5_moral_emotions_robertalarge_skfold_augmented.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203e61b-4382-45e7-9a26-69a13e39b71c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Experimentos Roberta Estructura Modificada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce702d8-6242-40be-bddf-cde4ecaf3fa8",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1063400-cc3e-483d-9f4b-00536918b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomDataset igual que el de la clase Roberta\n",
    "\n",
    "class RoBERTaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RoBERTaClass, self).__init__()\n",
    "        # Cargar el modelo preentrenado roberta-base\n",
    "        self.l1 = transformers.RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "        # Añadir Multi-Head Attention\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=768, num_heads=8, dropout=0.3, batch_first=True)\n",
    "\n",
    "        # Dropout para regularización\n",
    "        self.l2 = nn.Dropout(0.3)\n",
    "\n",
    "        # Capa lineal para clasificación binaria\n",
    "        self.l3 = nn.Linear(768, 1) \n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output = self.l1(ids, attention_mask=mask, return_dict=True)\n",
    "        hidden_states = output.last_hidden_state  # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # Paso 2: Aplicar Multi-Head Attention\n",
    "        attn_output, _ = self.multihead_attention(hidden_states, hidden_states, hidden_states, key_padding_mask=~mask.bool())\n",
    "\n",
    "        # Paso 3: Tomar el embedding del token [CLS] (posición 0)\n",
    "        cls_embedding = attn_output[:, 0, :]  # [CLS] después de atención [batch_size, hidden_dim]\n",
    "\n",
    "        # Paso 4: Aplicar Dropout\n",
    "        output_2 = self.l2(cls_embedding)\n",
    "\n",
    "        # Paso 5: Pasar por la capa de clasificación\n",
    "        output = self.l3(output_2).squeeze(1)\n",
    "\n",
    "        return output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RoBERTaClass().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c97479-469a-44f3-a38b-a21fb31bd9ac",
   "metadata": {},
   "source": [
    "# Experimento uniendo Bert y Roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9ee09-2da1-4c14-bbb6-35b7be564bd6",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed1fc0-6a7f-4d5f-ab43-ad3b2acb826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar los modelos y tokenizadores\n",
    "tokenizer_roberta = transformers.RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model_roberta = transformers.RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "tokenizer_bert = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Función para procesar texto y obtener el [CLS] de RoBERTa y BERT\n",
    "def process_text_with_metadatas(text, emotion, moral):\n",
    "    # Paso 1: Crear el texto completo con los metadatos\n",
    "    full_text = f\"{text} Este texto refleja la emoción {emotion} y la moral {moral}\"\n",
    "    \n",
    "    # Paso 2: Tokenizar el texto completo para RoBERTa\n",
    "    inputs_roberta = tokenizer_roberta(full_text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    outputs_roberta = model_roberta(**inputs_roberta)\n",
    "    cls_roberta = outputs_roberta.last_hidden_state[:, 0, :]  # [CLS] de RoBERTa\n",
    "    \n",
    "    # Paso 3: Tokenizar el texto completo también para BERT (usamos el mismo texto con metadatos)\n",
    "    inputs_bert = tokenizer_bert(full_text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    outputs_bert = model_bert(**inputs_bert)\n",
    "    cls_bert = outputs_bert.last_hidden_state[:, 0, :]  # [CLS] de BERT\n",
    "    \n",
    "    # Paso 4: Concatenar los [CLS] de RoBERTa y BERT\n",
    "    combined_cls = torch.cat((cls_roberta, cls_bert), dim=1)  # Concatenación a lo largo de las dimensiones de características\n",
    "    return combined_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c2f8e-a20e-4388-90fa-5c3819c7d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512  \n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "tokenizer = tokenizer_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbadbf-b3ca-407b-8c28-7a332322c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe['text']\n",
    "        self.targets = self.data['class']\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())  \n",
    "\n",
    "        # Procesar el texto con 3l contexto de emociones y moral y obtener el [CLS] concatenado\n",
    "        inputs = process_text_with_metadatas(text, self.data['max_emotion'][index], self.data['max_moral'][index])\n",
    "        \n",
    "        return {\n",
    "            'cls': inputs.squeeze(),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)}\n",
    "\n",
    "# Clasificador\n",
    "class ClassifierModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super(ClassifierModel, self).__init__()\n",
    "        # Capa densa para la clasificación\n",
    "        self.fc = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "¡model = ClassifierModel(input_dim=768 * 2)  # RoBERTa + BERT [CLS] (768 de cada uno)\n",
    "\n",
    "# Función de pérdida y el optimizador\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d77e6-a2b4-4ac9-b382-da1d19468cd5",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92389420-231b-460a-a6be-d45a7cf7b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader):\n",
    "    model.train()  \n",
    "    for _, data in enumerate(train_loader):\n",
    "        cls = data['cls']\n",
    "        targets = data['targets']\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(cls) \n",
    "        loss = loss_fn(outputs.squeeze(), targets)  \n",
    "\n",
    "        if _ % 5000 == 0:  \n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step()  \n",
    "\n",
    "def validation(model, data_loader):\n",
    "    model.eval()  \n",
    "    fin_targets = []  \n",
    "    fin_outputs = []  \n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for data in data_loader:\n",
    "            cls = data['cls']\n",
    "            targets = data['targets']\n",
    "\n",
    "            outputs = model(cls)  \n",
    "            outputs = torch.sigmoid(outputs).squeeze()  \n",
    "\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    return fin_outputs, fin_targets\n",
    "\n",
    "\n",
    "def evaluate_metrics(outputs, targets):\n",
    "    outputs = [1 if x > 0.5 else 0 for x in outputs]\n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(targets, outputs, average='binary')\n",
    "    mcc = matthews_corrcoef(targets, outputs)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc\n",
    "    }\n",
    "\n",
    "\n",
    "def cross_validate_model(model, dataframe, tokenizer, title, epochs=3, batch_size=16, k_folds=5):\n",
    "    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    metrics_list = [] \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataframe, dataframe['class'])):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "        train_df = dataframe.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = dataframe.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        train_set = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "        val_set = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train(epoch, model, train_loader)  # Entrenamiento\n",
    "\n",
    "        outputs, targets = validation(model, val_loader)\n",
    "        fold_metrics = evaluate_metrics(outputs, targets) \n",
    "        metrics_list.append(fold_metrics)\n",
    "        \n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.to_csv(f'metrics_{title}.csv', index=False)\n",
    "\n",
    "    print('Cross-validation complete')\n",
    "\n",
    "cross_validate_model(model, new_df, tokenizer, \"roberta_bert_combined\", epochs=EPOCHS, batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b9829-c1eb-411e-847c-0a212f27d881",
   "metadata": {},
   "source": [
    "## Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354ef16-009d-4760-9e90-ba5dde56ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/test/dataset_en_test_cleaned.csv\")\n",
    "test_df['class'] = test_df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "test_df = test_df[['text', 'class']].copy()\n",
    "test_df\n",
    "\n",
    "def process_text_test(text):\n",
    "    # Tokenizar el texto completo para RoBERTa\n",
    "    inputs_roberta = tokenizer_roberta(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    outputs_roberta = model_roberta(**inputs_roberta)\n",
    "    cls_roberta = outputs_roberta.last_hidden_state[:, 0, :]  # [CLS] de RoBERTa\n",
    "    \n",
    "    # Tokenizar el texto también para BERT\n",
    "    inputs_bert = tokenizer_bert(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    outputs_bert = model_bert(**inputs_bert)\n",
    "    cls_bert = outputs_bert.last_hidden_state[:, 0, :]  # [CLS] de BERT\n",
    "    \n",
    "    # Concatenar los [CLS] de RoBERTa y BERT\n",
    "    combined_cls = torch.cat((cls_roberta, cls_bert), dim=1)  # Concatenación a lo largo de las dimensiones de características\n",
    "    return combined_cls\n",
    "    \n",
    "def predict(text, model, tokenizer):\n",
    "    # Procesar el texto y obtener el [CLS] concatenado de RoBERTa y BERT\n",
    "    inputs = process_text_test(text)\n",
    "    inputs = inputs.squeeze()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)  \n",
    "        outputs = torch.sigmoid(outputs).squeeze()  \n",
    "\n",
    "        probability = outputs.item()  \n",
    "        prediction = 1 if probability >= 0.5 else 0 \n",
    "\n",
    "def test_and_evaluate(model, tokenizer, test_df, filename=\"test_results.json\"):\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        text = row['text']\n",
    "        prediction, probability = predict(text, model, tokenizer)\n",
    "        predictions.append(prediction)\n",
    "        probabilities.append(probability)\n",
    "\n",
    "    test_df['predictions'] = predictions\n",
    "    test_df['probabilities'] = probabilities\n",
    "    mcc = matthews_corrcoef(test_df['class'], test_df['predictions'])\n",
    "\n",
    "    results = classification_report(\n",
    "        test_df['class'],\n",
    "        test_df['predictions'],\n",
    "        target_names=['CONSPIRACY', 'CRITICAL'],\n",
    "        digits=5,\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    # Guardar los resultados y MCC \n",
    "    output_data = {\n",
    "        \"mcc\": mcc,\n",
    "        \"classification_report\": results\n",
    "    }\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "    print(f\"Test results saved to {filename}\")\n",
    "    print(f\"Test MCC = {mcc}\")\n",
    "\n",
    "test_df = pd.read_csv(\"data/test/dataset_en_test_cleaned.csv\")\n",
    "test_df['class'] = test_df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "test_df = test_df[['text', 'class']].copy()\n",
    "\n",
    "test_and_evaluate(model, tokenizer_roberta, test_df, filename=\"test_evaluation_results_bert_roberta_combined.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
