{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a769f72-5656-43d8-8154-d5ecbf1cdcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b65dc6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Eliminar enlaces (URLs)\n",
    "    text = re.sub(r'https?\\s*:\\s*//\\s*\\S+', '', text)\n",
    "    text = re.sub(r'www\\.?\\s*\\S+', '', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)    \n",
    "    # 2. Normalizar a minúsculas\n",
    "    text = text.lower()   \n",
    "    # 3. Eliminar caracteres especiales y números (mantener comas y puntos)\n",
    "    text = re.sub(r'[^a-z\\s,.]', '', text)  # Mantener comas y puntos\n",
    "    # 4. Eliminar múltiples espacios en blanco\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # 5. Eliminar los saltos de línea\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def clean_text_es(text):\n",
    "    # 1. Eliminar enlaces (URLs)\n",
    "    text = re.sub(r'https?\\s*:\\s*//\\s*\\S+', '', text)\n",
    "    text = re.sub(r'www\\.?\\s*\\S+', '', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    # 2. Normalizar a minúsculas\n",
    "    text = text.lower()   \n",
    "    # 3. Eliminar caracteres especiales y números (mantener comas y puntos)\n",
    "    text = re.sub(r'[^a-záéíóúñü\\s,.]', '', text)  # Mantener caracteres acentuados, comas y puntos   \n",
    "    # 4. Eliminar múltiples espacios en blanco\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # 5. Eliminar los saltos de línea\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98610ef4-8c0e-434b-b96d-60700d582427",
   "metadata": {},
   "source": [
    "# Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a2378d3-23e2-471e-ad5b-dc0f5a91cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(r\"data/test/dataset_en_test.json\")\n",
    "df['text'] = df['text'].apply(lambda text: clean_text_es(text))\n",
    "\n",
    "'''\n",
    "df.to_csv(r\"data/train/dataset_es_train_cleaned.csv\", index=False)\n",
    "\n",
    "df = pd.read_json(r\"data/train/dataset_en_train.json\")\n",
    "df['text'] = df['text'].apply(lambda text: clean_text(text))\n",
    "df.head()\n",
    "df.to_csv(r\"data/train/dataset_en_train_cleaned.csv\", index=False)'''\n",
    "df.to_csv(r\"data/test/dataset_en_test_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b696941-c24d-4a57-b139-effd5bcf4d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba22113-a128-4ff8-8c42-855f9df0f7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m deeply concerned pushing vaccination child dystopian experiment unknown episode rep louie gohmert r texas thedefender org defender fda eua covid shot child boy kid'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"data/train/dataset_en_train_augmented.csv\")\n",
    "df.loc[1].text\n",
    "df.loc[4001].text\n",
    "#buen ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aace10ed-611f-4b6e-93c0-edd338794e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84c80e-9c6b-450d-98bc-bf3ab311a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Procesando filas:  12%|█▏        | 471/4000 [46:49<5:35:25,  5.70s/it] "
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Importar tqdm\n",
    "\n",
    "# Cargar los modelos y tokenizadores de traducción\n",
    "model_name_es_en = \"Helsinki-NLP/opus-mt-es-en\"\n",
    "model_name_en_es = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "\n",
    "tokenizer_es_en = MarianTokenizer.from_pretrained(model_name_es_en)\n",
    "model_es_en = MarianMTModel.from_pretrained(model_name_es_en)\n",
    "\n",
    "tokenizer_en_es = MarianTokenizer.from_pretrained(model_name_en_es)\n",
    "model_en_es = MarianMTModel.from_pretrained(model_name_en_es)\n",
    "\n",
    "def translate_text(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    translated = model.generate(**inputs)\n",
    "    return tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
    "\n",
    "# Cargar el DataFrame\n",
    "df = pd.read_csv(\"data/train/dataset_es_train_cleaned.csv\")\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "# Iterar sobre el DataFrame con tqdm para la barra de progreso\n",
    "for i, fila in tqdm(df.iterrows(), total=df.shape[0], desc=\"Procesando filas\"):\n",
    "    # Traducir de español a inglés\n",
    "    text_en = translate_text(fila['text'], tokenizer_es_en, model_es_en)\n",
    "    # Traducir de vuelta de inglés a español\n",
    "    text_es_back = translate_text(text_en, tokenizer_en_es, model_en_es)\n",
    "\n",
    "    # Generar un nuevo ID aleatorio\n",
    "    id_new = ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n",
    "\n",
    "    # Crear una nueva fila con la traducción aumentada\n",
    "    new_row = {'id': id_new, 'text': text_es_back, 'category': fila['category']}\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Convertir la lista de filas nuevas a un DataFrame\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Concatenar el DataFrame original con el nuevo DataFrame\n",
    "df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame resultante\n",
    "df.to_csv('data/train/dataset_es_train_augmented.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb51d6a-aa82-4c99-983f-432d64a97d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i do nt know about you but i m getting extremely tired of the same posts about how corrupt the deep state cabal is over and over and over . if you are on my page then you already know how evil these people are . you do not need to be convinced . therefore hammering that into your psyche ad nasauem is akin to self torture . i just ca nt do it . i only post corrupt things when it s so ludicrous that it amuses me . other than that i ca nt stand to watch anymore of this . i d rather focus on god , memes , and news at the k foot level . thoughts'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train/dataset_en_train_cleaned.csv\")\n",
    "df.loc[3999].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "957d86a4-613b-41eb-bbf9-ec2ab0b900fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                          4NLk1\n",
       "text            I don't know about you, but I'm always extreme...\n",
       "category                                               CONSPIRACY\n",
       "annotations                                                   NaN\n",
       "spacy_tokens                                                  NaN\n",
       "Name: 7999, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train/dataset_en_train_augmented.csv\")\n",
    "df.loc[7999].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8bc57-2c82-400c-aaab-d21ae9b5dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Importar tqdm para la barra de progreso\n",
    "\n",
    "# Cargar los modelos y tokenizadores de traducción\n",
    "model_name_es_en = \"Helsinki-NLP/opus-mt-en-de\"\n",
    "model_name_en_es = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "\n",
    "tokenizer_es_en = MarianTokenizer.from_pretrained(model_name_es_en)\n",
    "model_es_en = MarianMTModel.from_pretrained(model_name_es_en)\n",
    "\n",
    "tokenizer_en_es = MarianTokenizer.from_pretrained(model_name_en_es)\n",
    "model_en_es = MarianMTModel.from_pretrained(model_name_en_es)\n",
    "\n",
    "def translate_text(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    translated = model.generate(**inputs)\n",
    "    return tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n",
    "\n",
    "# Cargar el DataFrame\n",
    "df = pd.read_csv(\"data/train/dataset_en_train_cleaned.csv\")\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "# Iterar sobre el DataFrame con tqdm para la barra de progreso\n",
    "for i, fila in tqdm(df.iterrows(), total=df.shape[0], desc=\"Procesando filas\"):\n",
    "    # Traducir de inglés a alemán\n",
    "    text_en = translate_text(fila['text'], tokenizer_es_en, model_es_en)\n",
    "    # Traducir de vuelta de alemán a inglés\n",
    "    text_es_back = translate_text(text_en, tokenizer_en_es, model_en_es)\n",
    "\n",
    "    # Generar un nuevo ID aleatorio\n",
    "    id_new = ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n",
    "\n",
    "    # Crear una nueva fila con la traducción aumentada\n",
    "    new_row = {'id': id_new, 'text': text_es_back, 'category': fila['category']}\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Convertir la lista de filas nuevas a un DataFrame\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Concatenar el DataFrame original con el nuevo DataFrame\n",
    "df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame resultante\n",
    "df.to_csv('data/train/dataset_en_train_augmented.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f150b1d1-19dc-46db-9b4c-1240a02fc04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No es un médico, no es un científico, no es un biólogo, es un simple ordenador incompetente que tuvo que robar sus ideas y software para steve puestos de trabajo creador de manzana que era el verdadero genio . este papanatos que es la única cosa que es un estafador que ni siquiera podría terminar si carrera universitaria y que se detuvo por abusar de un menor antes de ser repugnantemente rico , que ha ido muy bien el engaño como buenos expertos judeomasónicos en manipulación de usureria y mentiras de engaño , esta falsa filantropía , va de salvar al mundo un falso mentiroso nos dice y anticipa pandemias lo que la calificación médica científica tiene similar a ser el de poder y dinero y la personificada . no es una adivinadora . él es el propietario y máximo accionista de los mayores lobbys de este mundo que hará que la población de los laboratorios farmacéuticos , la gran farmacéutica , o la mafia farmacéutica que ha comprado y sobornado médicos , hospitales , políticos a seguir recogiendo fortunas del mundo basado en su plan de miedo de la población del mundo con virus inteligentes y cuenta .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv('data/train/dataset_es_train_augmented.csv')\n",
    "df.loc[7998].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
