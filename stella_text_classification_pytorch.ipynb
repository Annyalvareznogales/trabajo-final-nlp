{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLvGqxBNeVrR"
   },
   "source": [
    "# Fine Tuning Transformer for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pzM1_ykHaFur"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import json\n",
    "from transformers import AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NLxxwd1scQNv"
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCaDM5rkmsf9"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1732006247385,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "mZ7lTlkyaG7u",
    "outputId": "19435ba3-6504-40b9-9dc7-86d8529e28ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "CRITICAL      2621\n",
       "CONSPIRACY    1379\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train/dataset_en_train_completed.csv')\n",
    "df=df.iloc[:4000,:]\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rinAOGUjmsf-"
   },
   "source": [
    "# Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GhxP1owmsf_"
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/train/dataset_en_train_completed.csv')\n",
    "df= df.iloc[:4000]\n",
    "\n",
    "df_augmented= pd.read_csv('data/train/dataset_en_train_completed.csv')\n",
    "df_augmented= df_augmented.iloc[4000:]\n",
    "#df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4K5aVHFmsgA"
   },
   "outputs": [],
   "source": [
    "original_counts = df['category'].value_counts()\n",
    "df_conspiracy = df[df['category'] == 'CONSPIRACY']\n",
    "df_conspiracy_augmented = df_augmented[df_augmented['category'] == 'CONSPIRACY']\n",
    "critical_count = original_counts.get('CRITICAL', 0) \n",
    "conspiracy_count = original_counts.get('CONSPIRACY', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZNTqKKsmsgA"
   },
   "outputs": [],
   "source": [
    "df_conspiracy = df_augmented[df_augmented['category'] == 'CONSPIRACY']\n",
    "\n",
    "# Seleccionar 1242 filas aleatorias para balancear el dataset \n",
    "df_conspiracy_sampled = df_conspiracy.sample(n=1242, random_state=42)\n",
    "df_combined = pd.concat([df, df_conspiracy_sampled])\n",
    "\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "df=df_combined.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQKfvpCFmsgB",
    "outputId": "9b6ac026-77e5-442e-898a-bb3ef3725465"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how the cia is directly involved in every aspect of the creation of the vaccine passports . groups created by the cia like palantir , mitre , oracle , and google , funded through the cias venture capital firm , in q tel , are are involved . every one of them are listed on the organizational member lists of the private companies in charge of the creation of all worldwide passports . full article . dailyveracity . com the shadowy cia data firms behind the creation of digital vaccine passport ids full video . bitchute . com video ufysjysoe donna. The text reflects the emotion: inspiration and the moral value loyalty'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_context(df):\n",
    "    # Añade información contextual usando corchetes\n",
    "    df['text'] =   df['text'] + '. The text reflects the emotion: ' + df['max_emotion'] + ' and the moral value: ' + df['max_moral']\n",
    "    return df\n",
    "\n",
    "\n",
    "df=add_context(df)\n",
    "df.loc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B39VMmbEmsgC"
   },
   "source": [
    "# Transform label from categoric to numeric\n",
    "\n",
    "Critical = 1\n",
    "Conspirancy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixRQy14FmsgC",
    "outputId": "8eb05aa2-0098-4cae-96ea-c21d856e8339"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how the cia is directly involved in every aspe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elon musk admits i felt like i was dying after...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the uk gov. quietly published data confirming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the global economic terror regime, which is lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>confirmed pharma fags crashed into a covid vac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>coming soon doctors for covid ethics fourth sy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>the vaccine mandates as i said last year have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>Minority report in real life a group of social...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>This is the reason why the Cabal does not want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>did you know the cdc is actually a vaccine com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  class\n",
       "0     how the cia is directly involved in every aspe...      0\n",
       "1     elon musk admits i felt like i was dying after...      1\n",
       "2     the uk gov. quietly published data confirming ...      1\n",
       "3     the global economic terror regime, which is lo...      0\n",
       "4     confirmed pharma fags crashed into a covid vac...      1\n",
       "...                                                 ...    ...\n",
       "5237  coming soon doctors for covid ethics fourth sy...      1\n",
       "5238  the vaccine mandates as i said last year have ...      1\n",
       "5239  Minority report in real life a group of social...      0\n",
       "5240  This is the reason why the Cabal does not want...      0\n",
       "5241  did you know the cdc is actually a vaccine com...      1\n",
       "\n",
       "[5242 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "\n",
    "new_df = df[['text', 'class']].copy()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqveDcmDeVrZ"
   },
   "source": [
    "# Preparing the Dataset and Dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ikfbFlNHgi8T"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dunzhang/stella_en_400M_v5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oFOylAXqiNYK"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe['text']\n",
    "        self.targets = self.data['class']\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        # Tokenize the text\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        ids = inputs['input_ids'].squeeze()\n",
    "        mask = inputs['attention_mask'].squeeze()\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': ids,\n",
    "            'mask': mask,\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8Z3O2tFeVrb"
   },
   "source": [
    "# Creating the Neural Network for Fine Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xformers\n",
      "  Using cached xformers-0.0.28.post3.tar.gz (7.8 MB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\paula\\\\AppData\\\\Local\\\\Temp\\\\pip-install-oh4xa3sc\\\\xformers_fba3dc0ef01d47d5ab6988f6ff516857\\\\third_party\\\\flash-attention\\\\csrc\\\\composable_kernel\\\\client_example\\\\24_grouped_conv_activation\\\\grouped_convnd_bwd_data_bilinear\\\\grouped_conv_bwd_data_bilinear_residual_fp16.cpp'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830,
     "referenced_widgets": [
      "42195991074a4eb78247eecbdd0bd834",
      "c40e2d6629054e1fae9f506aae6db45a",
      "f0a1943bc20b427f97a4068aeb50d8d8",
      "e2d4b0a3ba474a47b4002571bc5f7e46",
      "84203a1a076349a3bde070cbda900601",
      "835049488c554ae2b05852b194b1ed9c",
      "d10a65de80304fa79b2e55e7bdc0d481",
      "3ba62a7dbd884db9a26c4e717d46ce9a",
      "2daf145267054614a40293de36d69f80",
      "bad21d3465fd4801acef250dcc7dbc82",
      "f3b84121f23344d29477fcf5e546f9bd"
     ]
    },
    "executionInfo": {
     "elapsed": 3486,
     "status": "ok",
     "timestamp": 1730571562136,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "DegHNyIEQxB2",
    "outputId": "c0f47e1c-46f0-44db-8c74-8fd8b3688efd"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "please install xformers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdunzhang/stella_en_400M_v5\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311_env\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:559\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    558\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m add_generation_mixin_to_remote_model(model_class)\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    560\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    561\u001b[0m     )\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311_env\\Lib\\site-packages\\transformers\\modeling_utils.py:4097\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4091\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[0;32m   4092\u001b[0m         config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[0;32m   4093\u001b[0m     )\n\u001b[0;32m   4095\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m   4096\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[1;32m-> 4097\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[0;32m   4100\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\dunzhang\\stella_en_400M_v5\\24e2e1ffe95e95d807989938a5f3b8c18ee651f5\\modeling.py:823\u001b[0m, in \u001b[0;36mNewModel.__init__\u001b[1;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m NewEmbeddings(config)\n\u001b[1;32m--> 823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m NewEncoder(config)\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;241m=\u001b[39m NewPooler(config) \u001b[38;5;28;01mif\u001b[39;00m add_pooling_layer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\dunzhang\\stella_en_400M_v5\\24e2e1ffe95e95d807989938a5f3b8c18ee651f5\\modeling.py:696\u001b[0m, in \u001b[0;36mNewEncoder.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([NewLayer(config) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\dunzhang\\stella_en_400M_v5\\24e2e1ffe95e95d807989938a5f3b8c18ee651f5\\modeling.py:696\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([NewLayer(config) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\dunzhang\\stella_en_400M_v5\\24e2e1ffe95e95d807989938a5f3b8c18ee651f5\\modeling.py:630\u001b[0m, in \u001b[0;36mNewLayer.__init__\u001b[1;34m(self, config, pack_qkv, use_memory_efficient_attention, attn_implementation)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_implementation \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    629\u001b[0m     use_memory_efficient_attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention \u001b[38;5;241m=\u001b[39m NEW_ATTENTION_CLASSES[attn_implementation](\n\u001b[0;32m    631\u001b[0m     config, pack_qkv\u001b[38;5;241m=\u001b[39mpack_qkv, use_memory_efficient_attention\u001b[38;5;241m=\u001b[39muse_memory_efficient_attention\n\u001b[0;32m    632\u001b[0m )\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m NewGatedMLP(config)\n\u001b[0;32m    635\u001b[0m ln_class \u001b[38;5;241m=\u001b[39m LAYER_NORM[config\u001b[38;5;241m.\u001b[39mlayer_norm_type]\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\dunzhang\\stella_en_400M_v5\\24e2e1ffe95e95d807989938a5f3b8c18ee651f5\\modeling.py:451\u001b[0m, in \u001b[0;36mNewAttention.__init__\u001b[1;34m(self, config, pack_qkv, use_memory_efficient_attention)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_efficient_attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m xops \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m xops\u001b[38;5;241m.\u001b[39mmemory_efficient_attention\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_memory_efficient_attention:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_efficient_attention \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease install xformers\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39munpad_inputs:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_memory_efficient_attention, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munpad only with xformers\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: please install xformers"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"dunzhang/stella_en_400M_v5\", trust_remote_code=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KnNeQx6SI78"
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUD8j0c7WsA-"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW9UZ-l8msgI"
   },
   "source": [
    "# Fine Tuning and Validating the Model (Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCj3VeoUAMy4"
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader):\n",
    "    model.train()  \n",
    "    for _, data in enumerate(train_loader):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()  # Limpiar los gradientes previos\n",
    "        outputs = model(ids, mask)  # Propagación hacia adelante\n",
    "        loss = loss_fn(outputs, targets) \n",
    "\n",
    "        if _ % 5000 == 0: \n",
    "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "        loss.backward()  # Propagación hacia atrás\n",
    "        optimizer.step()  # Actualizar los pesos del modelo\n",
    "\n",
    "def validation(model, data_loader, device):\n",
    "    model.eval()  \n",
    "    fin_targets = []  # etiquetas verdaderas\n",
    "    fin_outputs = []  # probabilidades de las predicciones\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for data in data_loader:\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            outputs = model(ids, mask) \n",
    "            outputs = torch.sigmoid(outputs)\n",
    "\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "    return fin_outputs, fin_targets\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate_metrics(outputs, targets):\n",
    "    # Convertir las salidas a 0 o 1 (clases predichas) basadas en el umbral 0.5\n",
    "    outputs = [1 if x > 0.5 else 0 for x in outputs]\n",
    "\n",
    "    # Calcular las métricas\n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(targets, outputs, average='binary')\n",
    "    mcc = matthews_corrcoef(targets, outputs)  # Calcular MCC\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc\n",
    "    }\n",
    "    # Imprimir los resultados\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "\n",
    "\n",
    "def cross_validate_model(model, dataframe, tokenizer,title, epochs=3, batch_size=16, k_folds=5):\n",
    "    #kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    #skfold es mejor opción cuando se tiene desbalanceo de datos\n",
    "    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    metrics_list = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataframe, dataframe['class'])):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "        train_df = dataframe.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = dataframe.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        train_set = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "        val_set = CustomDataset(val_df, tokenizer, MAX_LEN)\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train(epoch, model, train_loader)  \n",
    "\n",
    "        outputs, targets = validation(model, val_loader, device)\n",
    "        fold_metrics=evaluate_metrics(outputs, targets)\n",
    "        metrics_list.append(fold_metrics)\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "    # Guardar el DataFrame en un archivo CSV\n",
    "    metrics_df.to_csv(f'metrics{title}.csv', index=False)\n",
    "\n",
    "    print('Cross-validation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjH9wsfkAPwB",
    "outputId": "713a4a84-fae3-405a-f9c7-37bc9fcacf58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Epoch: 0, Loss: 0.7348228096961975\n",
      "Epoch: 1, Loss: 0.4871571660041809\n",
      "Epoch: 2, Loss: 0.018146932125091553\n",
      "\n",
      "Fold 2/5\n",
      "Epoch: 0, Loss: 0.007466912269592285\n",
      "Epoch: 1, Loss: 0.008322915062308311\n",
      "Epoch: 2, Loss: 0.0579494945704937\n",
      "\n",
      "Fold 3/5\n",
      "Epoch: 0, Loss: 0.003274182789027691\n",
      "Epoch: 1, Loss: 0.0032785036601126194\n",
      "Epoch: 2, Loss: 0.0026664207689464092\n",
      "\n",
      "Fold 4/5\n",
      "Epoch: 0, Loss: 0.008489318192005157\n",
      "Epoch: 1, Loss: 0.004815469030290842\n",
      "Epoch: 2, Loss: 0.0007440482149831951\n",
      "\n",
      "Fold 5/5\n",
      "Epoch: 0, Loss: 0.00466996431350708\n",
      "Epoch: 1, Loss: 0.004115194547921419\n",
      "Epoch: 2, Loss: 0.001830673310905695\n",
      "Cross-validation complete\n"
     ]
    }
   ],
   "source": [
    "# cambiar nombre de archivo que se guarda\n",
    "cross_validate_model(model, new_df, tokenizer, 'moral_emo_512_8_2e5_rl_skfold_augmented',epochs=3, batch_size=TRAIN_BATCH_SIZE, k_folds=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbQB5e2-eVre"
   },
   "source": [
    "# Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbRCa-DgtmOe"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"roberta_large_finetuned_model_en.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bYVOWinuxg6"
   },
   "source": [
    "# Load the Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2989,
     "status": "ok",
     "timestamp": 1730569245723,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "WdgvYxwBuxzM",
    "outputId": "be13b073-b546-4f0a-d382-f415b0aa2a9a"
   },
   "outputs": [],
   "source": [
    "# Define the paths to save the model and tokenizer\n",
    "'''\n",
    "MODEL_PATH = \"./model/roberta_finetuned_model.pth\"\n",
    "\n",
    "loaded_model = RoBERTaClass()\n",
    "loaded_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXrZVs7VuPyU"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1730569342132,
     "user": {
      "displayName": "Anny Álvarez",
      "userId": "01047458995033959693"
     },
     "user_tz": -60
    },
    "id": "GUnpQCwytmRR",
    "outputId": "8a5d698a-c2dd-4f8a-ba8a-4a9e19fcd156"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elon now confirming what we ve been suspecting...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keeping the pressure on the police to uphold t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe effective the greatest lie ever told . th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdc report admits . million people in the usa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how to use health to acquire totalitarian cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>john d. rockefeller wiped out natural cures to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>fact check biden white house falsely accuses d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>w onset acral hand lesions following mrna vacc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>we will fire unvaccinated workers cohen hadad ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>they are gearing up for the booster kill shot ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  class\n",
       "0    elon now confirming what we ve been suspecting...      0\n",
       "1    keeping the pressure on the police to uphold t...      0\n",
       "2    safe effective the greatest lie ever told . th...      1\n",
       "3    cdc report admits . million people in the usa ...      1\n",
       "4    how to use health to acquire totalitarian cont...      0\n",
       "..                                                 ...    ...\n",
       "995  john d. rockefeller wiped out natural cures to...      0\n",
       "996  fact check biden white house falsely accuses d...      1\n",
       "997  w onset acral hand lesions following mrna vacc...      1\n",
       "998  we will fire unvaccinated workers cohen hadad ...      1\n",
       "999  they are gearing up for the booster kill shot ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"data/test/dataset_en_test_cleaned.csv\")\n",
    "test_df['class'] = test_df['category'].apply(lambda x: 1 if x == 'CRITICAL' else 0)\n",
    "test_df = test_df[['text', 'class']].copy()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3M7c-GJjmsgO",
    "outputId": "851823ab-4711-48f0-fb41-323eefce949e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results saved to test_evaluation_results_512_2e5_moral_emotions_robertalarge_skfold_augmented.json\n",
      "Test MCC = 0.8244584282457748\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "def predict(text, model, tokenizer):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    ids = inputs['input_ids'].to(device)\n",
    "    mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(ids, mask)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
    "        prediction = 1 if probabilities[0] >= 0.5 else 0\n",
    "\n",
    "    return prediction, probabilities[0]\n",
    "\n",
    "\n",
    "def test_and_evaluate(model, tokenizer, test_df, filename=\"test_results.json\"):\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        text = row['text']\n",
    "        prediction, probability = predict(text, model, tokenizer)  \n",
    "        predictions.append(prediction)\n",
    "        probabilities.append(probability)\n",
    "\n",
    "    test_df['predictions'] = predictions\n",
    "    test_df['probabilities'] = probabilities\n",
    "\n",
    "    mcc = matthews_corrcoef(test_df['class'], test_df['predictions'])\n",
    "    results = classification_report(\n",
    "        test_df['class'],\n",
    "        test_df['predictions'],\n",
    "        target_names=['CONSPIRANCY', 'CRITICAL'], \n",
    "        digits=5,\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    output_data = {\n",
    "        \"mcc\": mcc,\n",
    "        \"classification_report\": results\n",
    "    }\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "    print(f\"Test results saved to {filename}\")\n",
    "    print(f\"Test MCC = {mcc}\")\n",
    "\n",
    "# Example usage:\n",
    "test_and_evaluate(model, tokenizer, test_df, filename=\"test_evaluation_results_512_2e5_moral_emotions_robertalarge_skfold_augmented.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TatHpXamsgP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lra-4n0msgP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BP9FXtImsgP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oQ-kVEamsgQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfmCTLPqmsgQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMIhDIsnmsgQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8C1zOKlmsgQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1MlYXhBkYvnDDxcjwBI9dcnzHDC8YhlRY",
     "timestamp": 1732006303116
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2daf145267054614a40293de36d69f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ba62a7dbd884db9a26c4e717d46ce9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42195991074a4eb78247eecbdd0bd834": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c40e2d6629054e1fae9f506aae6db45a",
       "IPY_MODEL_f0a1943bc20b427f97a4068aeb50d8d8",
       "IPY_MODEL_e2d4b0a3ba474a47b4002571bc5f7e46"
      ],
      "layout": "IPY_MODEL_84203a1a076349a3bde070cbda900601"
     }
    },
    "835049488c554ae2b05852b194b1ed9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84203a1a076349a3bde070cbda900601": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bad21d3465fd4801acef250dcc7dbc82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c40e2d6629054e1fae9f506aae6db45a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_835049488c554ae2b05852b194b1ed9c",
      "placeholder": "​",
      "style": "IPY_MODEL_d10a65de80304fa79b2e55e7bdc0d481",
      "value": "model.safetensors: 100%"
     }
    },
    "d10a65de80304fa79b2e55e7bdc0d481": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2d4b0a3ba474a47b4002571bc5f7e46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bad21d3465fd4801acef250dcc7dbc82",
      "placeholder": "​",
      "style": "IPY_MODEL_f3b84121f23344d29477fcf5e546f9bd",
      "value": " 440M/440M [00:02&lt;00:00, 187MB/s]"
     }
    },
    "f0a1943bc20b427f97a4068aeb50d8d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ba62a7dbd884db9a26c4e717d46ce9a",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2daf145267054614a40293de36d69f80",
      "value": 440449768
     }
    },
    "f3b84121f23344d29477fcf5e546f9bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
